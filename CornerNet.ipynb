{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mwebzuICC2eh"
   },
   "source": [
    "# CornerNet \n",
    "\n",
    "By Group C (Polina Tsvilodub, Jan Kettler, Malte Heyen, Lukas Schießer, Shantanu Audichya)\n",
    "\n",
    "CornerNet was first introduced by Law & Deng (2019) [1] and presents an alternative approach to object detection via detecting keypoints of the object bounding box. A convolutional network predicts two sets of heatmaps to  represent the locations of corners of different object categories, one set for the top-left corners and the other for the bottom-right corners. The network also predicts an embedding vector for each detected corner and is trained to minimize the distance between the embeddings of two corners from the same object. To produce tighter bounding boxes, the network also predicts offsets of the corners [1]. \n",
    "\n",
    "This notebook presents the implementation of CornerNet in TensorFlow as described [here](https://github.com/makalo/CornerNet), along with a toy example of model training on the MS COCO dataset. The original implementation can be found [here](https://github.com/princeton-vl/CornerNet).\n",
    "\n",
    "The notebook is structured as follows: The original code from the repo referenced above is presented here as a single notebook and thoroughly commented, in order to facilitate self-study. Then, the model is trained on the [MS COCO dataset](https://cocodataset.org/#download). The original code is adjusted such as to be executable in a jupyter notebook. \n",
    "\n",
    "**! Warning !**\n",
    "\n",
    "The notebook is only intended as an example. It only utilizes a small subset of the dataset---it actually trains on the 2017 validation set with 5000 images. Furthermore, the training duration is manually set to a 100 training steps only for purposes of making a quick example. These setting already require a lot of memory, so *the notebook should be run on Google Colab (using a GPU accelerator)!* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3sQv4IB_ri25"
   },
   "source": [
    "## Example\n",
    "As an example of the performance of the model, below you can see images with detected objects generated during training of the model.   \n",
    "\n",
    "![Example of CornerNet output](example_images/0.jpg)\n",
    "![Example of CornerNet output](example_images/10.jpg)\n",
    "![Example of CornerNet output](example_images/20.jpg)\n",
    "![Example of CornerNet output](example_images/30.jpg)\n",
    "![Example of CornerNet output](example_images/40.jpg)\n",
    "![Example of CornerNet output](example_images/50.jpg)\n",
    "![Example of CornerNet output](example_images/60.jpg)\n",
    "![Example of CornerNet output](example_images/70.jpg)\n",
    "![Example of CornerNet output](example_images/80.jpg)\n",
    "![Example of CornerNet output](example_images/90.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RAaA8_17Si5X"
   },
   "source": [
    "## Preparing the tools\n",
    "First, download the COCO API and the dataset to the local directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rolXvM7aiLrt",
    "outputId": "70c6b6ad-94af-432a-ad06-128fd71ab1b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘data’: File exists\n",
      "fatal: destination path 'cocoapi' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "# create data directory\n",
    "!mkdir data\n",
    "# clone COCO API\n",
    "!cd data; git clone https://github.com/cocodataset/cocoapi.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BCDPzp8TQTZQ",
    "outputId": "b66dd825-2950-48ed-cebd-81197a1ba740"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python setup.py build_ext --inplace\n",
      "running build_ext\n",
      "skipping 'pycocotools/_mask.c' Cython extension (up-to-date)\n",
      "building 'pycocotools._mask' extension\n",
      "creating build\n",
      "creating build/common\n",
      "creating build/temp.linux-x86_64-3.7\n",
      "creating build/temp.linux-x86_64-3.7/pycocotools\n",
      "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I../common -I/usr/include/python3.7m -c ../common/maskApi.c -o build/temp.linux-x86_64-3.7/../common/maskApi.o -Wno-cpp -Wno-unused-function -std=c99\n",
      "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleDecode\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K../common/maskApi.c:46:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "       \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; v=!v; }}\n",
      "       \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:46:49:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
      "       for( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; \u001b[01;36m\u001b[Kv\u001b[m\u001b[K=!v; }}\n",
      "                                                 \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrPoly\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K../common/maskApi.c:166:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); x[k]=x[0];\n",
      "   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:166:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
      "   for(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); \u001b[01;36m\u001b[Kx\u001b[m\u001b[K[k]=x[0];\n",
      "                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:167:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); y[k]=y[0];\n",
      "   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:167:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
      "   for(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); \u001b[01;36m\u001b[Ky\u001b[m\u001b[K[k]=y[0];\n",
      "                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToString\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K../common/maskApi.c:212:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "       \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(more) c |= 0x20; c+=48; s[p++]=c;\n",
      "       \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:212:27:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
      "       if(more) c |= 0x20; \u001b[01;36m\u001b[Kc\u001b[m\u001b[K+=48; s[p++]=c;\n",
      "                           \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrString\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K../common/maskApi.c:220:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "   \u001b[01;35m\u001b[Kwhile\u001b[m\u001b[K( s[m] ) m++; cnts=malloc(sizeof(uint)*m); m=0;\n",
      "   \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:220:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’\n",
      "   while( s[m] ) m++; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K=malloc(sizeof(uint)*m); m=0;\n",
      "                      \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:228:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "     \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(m>2) x+=(long) cnts[m-2]; cnts[m++]=(uint) x;\n",
      "     \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:228:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
      "     if(m>2) x+=(long) cnts[m-2]; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K[m++]=(uint) x;\n",
      "                                  \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToBbox\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K../common/maskApi.c:141:31:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kxp\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
      "       if(j%2==0) xp=x; else if\u001b[01;35m\u001b[K(\u001b[m\u001b[Kxp<x) { ys=0; ye=h-1; }\n",
      "                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I../common -I/usr/include/python3.7m -c pycocotools/_mask.c -o build/temp.linux-x86_64-3.7/pycocotools/_mask.o -Wno-cpp -Wno-unused-function -std=c99\n",
      "creating build/lib.linux-x86_64-3.7\n",
      "creating build/lib.linux-x86_64-3.7/pycocotools\n",
      "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-OGiuun/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/../common/maskApi.o build/temp.linux-x86_64-3.7/pycocotools/_mask.o -o build/lib.linux-x86_64-3.7/pycocotools/_mask.cpython-37m-x86_64-linux-gnu.so\n",
      "copying build/lib.linux-x86_64-3.7/pycocotools/_mask.cpython-37m-x86_64-linux-gnu.so -> pycocotools\n",
      "rm -rf build\n"
     ]
    }
   ],
   "source": [
    "!cd data/cocoapi/PythonAPI/; make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PWh8-9yMmlcl"
   },
   "source": [
    "The MS COCO dataset has a particular format. It provides sets of annotated training, validation and testing images along with corresponding `.json` files containing the actual annotations. These annotations consist of class labels, bounding box coordinates and other meta-information. There are 80 classes in the dataset. The size of the splits depends on the version of the dataset. Here, the 2017 validation split containing 5000 images is used. Alternatively to the API, the 2014 dataset could be accessed via `tensorflow_datasets.load('Coco')` (**Warning**: this might be too large for the available Google Colab memory).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Eyae4iIUlRM",
    "outputId": "b6de327d-c9d3-4165-a52d-5b8c1715b635"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘annotations’: File exists\n",
      "--2021-05-27 13:32:00--  http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
      "Resolving images.cocodataset.org (images.cocodataset.org)... 52.217.75.100\n",
      "Connecting to images.cocodataset.org (images.cocodataset.org)|52.217.75.100|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 252907541 (241M) [application/zip]\n",
      "Saving to: ‘data/cocoapi/annotations/annotations_trainval2017.zip.3’\n",
      "\n",
      "annotations_trainva 100%[===================>] 241.19M  89.7MB/s    in 2.7s    \n",
      "\n",
      "2021-05-27 13:32:03 (89.7 MB/s) - ‘data/cocoapi/annotations/annotations_trainval2017.zip.3’ saved [252907541/252907541]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create directory `annotations` in `cocoapi` and download chosen annotations from here: http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
    "!cd data/cocoapi; mkdir annotations; \n",
    "!wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip -P data/cocoapi/annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lc85IwllQKc-",
    "outputId": "28923366-2bb6-4c1e-8f2f-ca6226943d6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘images’: File exists\n",
      "--2021-05-27 13:32:03--  http://images.cocodataset.org/zips/val2017.zip\n",
      "Resolving images.cocodataset.org (images.cocodataset.org)... 52.217.75.100\n",
      "Connecting to images.cocodataset.org (images.cocodataset.org)|52.217.75.100|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 815585330 (778M) [application/zip]\n",
      "Saving to: ‘data/cocoapi/images/val2017.zip.3’\n",
      "\n",
      "val2017.zip.3       100%[===================>] 777.80M  99.4MB/s    in 8.1s    \n",
      "\n",
      "2021-05-27 13:32:11 (95.9 MB/s) - ‘data/cocoapi/images/val2017.zip.3’ saved [815585330/815585330]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create the directory `images` in cocoapi \n",
    "# we only use the validation set for training the model because the memory availavle in colab isn't sufficient for managing the 2014 training data\n",
    "# download zip files from https://cocodataset.org/#download (2017 Val images and 2017 test images) to `images`\n",
    "!cd data/cocoapi; mkdir images;\n",
    "!wget \"http://images.cocodataset.org/zips/val2017.zip\" -P data/cocoapi/images/; \n",
    "# download 2017 test data, if necessary; it is not used here  \n",
    "#!wget \"http://images.cocodataset.org/zips/test2017.zip\" -P data/cocoapi/images/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F11QcB82kYM9",
    "outputId": "b611ce82-3d38-48d5-800f-05c2dc36fb4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  data/cocoapi/annotations/annotations_trainval2017.zip\n",
      "replace data/cocoapi/annotations/instances_train2017.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
     ]
    }
   ],
   "source": [
    "#unzip annotations\n",
    "!unzip data/cocoapi/annotations/annotations_trainval2017.zip -d data/cocoapi/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pg8xO-Z6Fjg7",
    "outputId": "31ca7434-650d-48c6-ec5e-224955ccc553"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  data/cocoapi/images/val2017.zip\n",
      "replace data/cocoapi/images/val2017/000000212226.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
     ]
    }
   ],
   "source": [
    "# unzip validation data\n",
    "!unzip data/cocoapi/images/val2017.zip -d data/cocoapi/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lJer_JOgkvrQ"
   },
   "outputs": [],
   "source": [
    "# not used for this example\n",
    "# unzip test data\n",
    "#!unzip data/cocoapi/images/test2017.zip -d data/cocoapi/images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xqT4rLIzokBG"
   },
   "source": [
    "### Load the libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2j2ckdytqm3h"
   },
   "source": [
    "Here, the libraries used in the code are imported. Note that an older version of TensorFlow is used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "efnBQaFBmQzf",
    "outputId": "1914fa7e-91db-4d6a-af92-3586e48bd054"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 1.x selected.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 1.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vyg7XrjNoz6Y"
   },
   "outputs": [],
   "source": [
    "# libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "# utility libraries\n",
    "import sys\n",
    "import cv2\n",
    "from google.colab.patches import cv2_imshow\n",
    "import random\n",
    "import string\n",
    "# libraries for handling the data\n",
    "sys.path.append(\"./data/cocoapi/PythonAPI/\")\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R1BvHD3VmtbW",
    "outputId": "cffa9412-791e-4146-8fc0-28b00f55f329"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.2\n"
     ]
    }
   ],
   "source": [
    "# check\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "npXSAqxKXUUF"
   },
   "source": [
    "## Define helper modules\n",
    "\n",
    "In the helper modules, the corner pooling function, the forward pass and the computation of the loss are implemented. The forward module also includes NMS. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pSEveB5PK01y"
   },
   "outputs": [],
   "source": [
    "# configuration of the training parameters\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        self._configs = {}\n",
    "        self._configs[\"dataset\"] = None\n",
    "\n",
    "\n",
    "        # Training Config\n",
    "        self._configs[\"display\"]           = 5\n",
    "        self._configs[\"decay_step\"]        = 12000 # learning rate decay\n",
    "        self._configs[\"epoch_num\"]         = 1 # 100 # nr of training epochs; 1 for example purposes\n",
    "        self._configs[\"stepsize\"]          = 450000\n",
    "        self._configs[\"learning_rate\"]     = 0.00025 # initial larning rate\n",
    "        self._configs[\"decay_rate\"]        = 0.95\n",
    "        self._configs[\"max_iter\"]          = 500000\n",
    "        self._configs[\"val_iter\"]          = 100\n",
    "        self._configs[\"batch_size\"]        = 5 # batch size\n",
    "        self._configs[\"snapshot_name\"]     = 'corner_net'\n",
    "        self._configs[\"prefetch_size\"]     = 100\n",
    "        self._configs[\"weight_decay\"]      = False\n",
    "        self._configs[\"weight_decay_rate\"] = 1e-5\n",
    "        self._configs[\"weight_decay_type\"] = \"l2\"\n",
    "        self._configs[\"pretrain\"]          = None\n",
    "        self._configs[\"opt_algo\"]          = \"adam\" # optimizer\n",
    "        self._configs[\"chunk_sizes\"]       = [4, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n",
    "\n",
    "\n",
    "\n",
    "        # Directories\n",
    "        # directory where the API and the data were cloned to\n",
    "        self._configs[\"data_dir\"]   = \"./data\" \n",
    "        # created during execution \n",
    "        self._configs[\"cache_dir\"]  = \"./cache\"\n",
    "        self._configs[\"config_dir\"] = \"./config\"\n",
    "        self._configs[\"result_dir\"] = \"./results\"\n",
    "        self._configs[\"debug_dir\"]   = \"./debug\"\n",
    "\n",
    "        # Split\n",
    "        self._configs[\"train_split\"] = \"trainval\" \n",
    "        self._configs[\"val_split\"]   = \"minival\" \n",
    "        self._configs[\"test_split\"]  = \"testdev\"\n",
    "\n",
    "        # Rng\n",
    "        self._configs[\"data_rng\"] = np.random.RandomState(123)\n",
    "        self._configs[\"nnet_rng\"] = np.random.RandomState(317)\n",
    "\n",
    "        #data_config\n",
    "        self._configs[\"categories\"]        =80 # number of categories\n",
    "        self._configs[\"rand_scale_min\"]    =0.6 \n",
    "        self._configs[\"rand_scale_max\"]    =1.4\n",
    "        self._configs[\"rand_scale_step\"]   =0.1\n",
    "        self._configs[\"rand_scales\"]       =[0.5,0.75,1,1.25,1.5]\n",
    "        self._configs[\"rand_crop\"]         =True # crop images during preprocessing\n",
    "        self._configs[\"rand_color\"]        =True # add random color perturbations\n",
    "        self._configs[\"border\"]            =128\n",
    "        self._configs[\"gaussian_bump\"]     =True\n",
    "        self._configs[\"input_size\"]        =[511,511] # input resolution\n",
    "        self._configs[\"output_sizes\"]      =[[128,128]] # training resolution\n",
    "        self._configs[\"test_scales\"]       =[0.5,0.75,1,1.25,1.5]\n",
    "        self._configs[\"top_k\"]             =100\n",
    "        self._configs[\"ae_threshold\"]      =0.5\n",
    "        self._configs[\"nms_threshold\"]     =0.5 # NMS threshold\n",
    "        self._configs[\"merge_bbox\"]        =True\n",
    "        self._configs[\"weight_exp\"]        =10\n",
    "        self._configs[\"max_per_image\"]     =100\n",
    "        self._configs[\"gaussian_radius\"]   =-1 # radius of 2D Gaussian heatmap for corner detection\n",
    "        self._configs[\"gaussian_iou\"]      =0.7 # IoU threshold\n",
    "\n",
    "# set cofigurations\n",
    "    @property\n",
    "    def gaussian_iou(self):\n",
    "        return self._configs[\"gaussian_iou\"]\n",
    "    @property\n",
    "    def gaussian_radius(self):\n",
    "        return self._configs[\"gaussian_radius\"]\n",
    "    @property\n",
    "    def categories(self):\n",
    "        return self._configs[\"categories\"]\n",
    "    @property\n",
    "    def rand_scale_min(self):\n",
    "        return self._configs[\"rand_scale_min\"]\n",
    "    @property\n",
    "    def rand_scale_max(self):\n",
    "        return self._configs[\"rand_scale_max\"]\n",
    "    @property\n",
    "    def rand_scale_step(self):\n",
    "        return self._configs[\"rand_scale_step\"]\n",
    "    @property\n",
    "    def rand_scales(self):\n",
    "        return self._configs[\"rand_scales\"]\n",
    "    @property\n",
    "    def rand_crop(self):\n",
    "        return self._configs[\"rand_crop\"]\n",
    "    @property\n",
    "    def rand_color(self):\n",
    "        return self._configs[\"rand_color\"]\n",
    "    @property\n",
    "    def border(self):\n",
    "        return self._configs[\"border\"]\n",
    "    @property\n",
    "    def gaussian_bump(self):\n",
    "        return self._configs[\"gaussian_bump\"]\n",
    "    @property\n",
    "    def input_size(self):\n",
    "        return self._configs[\"input_size\"]\n",
    "    @property\n",
    "    def output_sizes(self):\n",
    "        return self._configs[\"output_sizes\"]\n",
    "    @property\n",
    "    def test_scales(self):\n",
    "        return self._configs[\"test_scales\"]\n",
    "    @property\n",
    "    def top_k(self):\n",
    "        return self._configs[\"top_k\"]\n",
    "    @property\n",
    "    def ae_threshold(self):\n",
    "        return self._configs[\"ae_threshold\"]\n",
    "    @property\n",
    "    def nms_threshold(self):\n",
    "        return self._configs[\"nms_threshold\"]\n",
    "    @property\n",
    "    def merge_bbox(self):\n",
    "        return self._configs[\"merge_bbox\"]\n",
    "    @property\n",
    "    def weight_exp(self):\n",
    "        return self._configs[\"weight_exp\"]\n",
    "    @property\n",
    "    def max_per_image(self):\n",
    "        return self._configs[\"max_per_image\"]\n",
    "    @property\n",
    "    def chunk_sizes(self):\n",
    "        return self._configs[\"chunk_sizes\"]\n",
    "\n",
    "    @property\n",
    "    def train_split(self):\n",
    "        return self._configs[\"train_split\"]\n",
    "\n",
    "    @property\n",
    "    def val_split(self):\n",
    "        return self._configs[\"val_split\"]\n",
    "\n",
    "    @property\n",
    "    def test_split(self):\n",
    "        return self._configs[\"test_split\"]\n",
    "\n",
    "    @property\n",
    "    def full(self):\n",
    "        return self._configs\n",
    "\n",
    "    @property\n",
    "    def sampling_function(self):\n",
    "        return self._configs[\"sampling_function\"]\n",
    "\n",
    "    @property\n",
    "    def data_rng(self):\n",
    "        return self._configs[\"data_rng\"]\n",
    "\n",
    "    @property\n",
    "    def nnet_rng(self):\n",
    "        return self._configs[\"nnet_rng\"]\n",
    "\n",
    "    @property\n",
    "    def opt_algo(self):\n",
    "        return self._configs[\"opt_algo\"]\n",
    "\n",
    "    @property\n",
    "    def weight_decay_type(self):\n",
    "        return self._configs[\"weight_decay_type\"]\n",
    "\n",
    "    @property\n",
    "    def prefetch_size(self):\n",
    "        return self._configs[\"prefetch_size\"]\n",
    "\n",
    "    @property\n",
    "    def pretrain(self):\n",
    "        return self._configs[\"pretrain\"]\n",
    "\n",
    "    @property\n",
    "    def weight_decay_rate(self):\n",
    "        return self._configs[\"weight_decay_rate\"]\n",
    "\n",
    "    @property\n",
    "    def weight_decay(self):\n",
    "        return self._configs[\"weight_decay\"]\n",
    "\n",
    "    @property\n",
    "    def result_dir(self):\n",
    "        result_dir = os.path.join(self._configs[\"result_dir\"], self.snapshot_name)\n",
    "        if not os.path.exists(result_dir):\n",
    "            os.makedirs(result_dir)\n",
    "        return result_dir\n",
    "    @property\n",
    "    def debug_dir(self):\n",
    "        debug_dir = os.path.join(self.cache_dir, \"debug\")\n",
    "        if not os.path.exists(debug_dir):\n",
    "            os.makedirs(debug_dir)\n",
    "        return debug_dir\n",
    "\n",
    "    @property\n",
    "    def dataset(self):\n",
    "        return self._configs[\"dataset\"]\n",
    "\n",
    "    @property\n",
    "    def snapshot_name(self):\n",
    "        return self._configs[\"snapshot_name\"]\n",
    "\n",
    "    @property\n",
    "    def snapshot_dir(self):\n",
    "        snapshot_dir = os.path.join(self.cache_dir, \"nnet\", self.snapshot_name)\n",
    "\n",
    "        if not os.path.exists(snapshot_dir):\n",
    "            os.makedirs(snapshot_dir)\n",
    "\n",
    "        return snapshot_dir\n",
    "\n",
    "    @property\n",
    "    def snapshot_file(self):\n",
    "        snapshot_file = os.path.join(self.snapshot_dir, self.snapshot_name + \".ckpt\")\n",
    "        return snapshot_file\n",
    "\n",
    "    @property\n",
    "    def config_dir(self):\n",
    "        return self._configs[\"config_dir\"]\n",
    "\n",
    "    @property\n",
    "    def batch_size(self):\n",
    "        return self._configs[\"batch_size\"]\n",
    "    @property\n",
    "    def epoch_num(self):\n",
    "        return self._configs[\"epoch_num\"]\n",
    "\n",
    "\n",
    "    @property\n",
    "    def max_iter(self):\n",
    "        return self._configs[\"max_iter\"]\n",
    "\n",
    "    @property\n",
    "    def learning_rate(self):\n",
    "        return self._configs[\"learning_rate\"]\n",
    "\n",
    "    @property\n",
    "    def decay_rate(self):\n",
    "        return self._configs[\"decay_rate\"]\n",
    "    @property\n",
    "    def decay_step(self):\n",
    "        return self._configs[\"decay_step\"]\n",
    "\n",
    "    @property\n",
    "    def stepsize(self):\n",
    "        return self._configs[\"stepsize\"]\n",
    "\n",
    "    @property\n",
    "    def snapshot(self):\n",
    "        return self._configs[\"snapshot\"]\n",
    "\n",
    "    @property\n",
    "    def display(self):\n",
    "        return self._configs[\"display\"]\n",
    "\n",
    "    @property\n",
    "    def val_iter(self):\n",
    "        return self._configs[\"val_iter\"]\n",
    "\n",
    "    @property\n",
    "    def data_dir(self):\n",
    "        return self._configs[\"data_dir\"]\n",
    "\n",
    "    @property\n",
    "    def cache_dir(self):\n",
    "        if not os.path.exists(self._configs[\"cache_dir\"]):\n",
    "            os.makedirs(self._configs[\"cache_dir\"])\n",
    "        return self._configs[\"cache_dir\"]\n",
    "\n",
    "    def update_config(self, new):\n",
    "        for key in new:\n",
    "            if key in self._configs:\n",
    "                self._configs[key] = new[key]\n",
    "\n",
    "cfg = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WY3rD6mkCyDf"
   },
   "source": [
    "### Define submodules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mBl0j58XyijZ"
   },
   "source": [
    "Below, the corner pooling functions are defined. This is necessary to determine if a pixel is a top-left / bottom-right corner, since images often do not explicitly contain object corners. Therefore, we need to look horizontally towards the right for the top-most boundary of an object and vertically towards the bottom for the left-most boundary. To do this, explicit prior knowledge is encoded. Essentially, the feature maps produced by the convolutional feature extractor are max-pooled, and used to predict heatmaps, embeddings and offsets. The architecture of these prediction modules can be seen below.\n",
    "\n",
    "![Corner prediction module](examples/prediction_module.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vMnoFfe3oiwK"
   },
   "outputs": [],
   "source": [
    "# define helper modules\n",
    "\n",
    "# corner pooling module\n",
    "def TopPool(inputs):\n",
    "    #forward\n",
    "    def forward(inputs):\n",
    "        out=tf.expand_dims(tf.reduce_max(inputs,1),1)\n",
    "        i=tf.constant(1)\n",
    "        batch,h,w,c=inputs.get_shape().as_list()\n",
    "        def cond(i,out):\n",
    "            return i < h\n",
    "        def body(i,out):\n",
    "            d=tf.expand_dims(tf.reduce_max(inputs[:,i:,:,:],1),1)\n",
    "            out=tf.concat((out,d),1)\n",
    "            i = i + 1\n",
    "            return i,out\n",
    "        _,out = tf.while_loop(cond, body, [i,out],shape_invariants= [i.get_shape(), tf.TensorShape([batch,None,w,c])])\n",
    "        return out\n",
    "    #backward\n",
    "    def backward(inputs,dy):\n",
    "        zeros=tf.expand_dims(tf.zeros_like(inputs[:,-1,:,:]),1)\n",
    "        ones=tf.expand_dims(tf.ones_like(inputs[:,-1,:,:]),1)\n",
    "        mask=tf.expand_dims(tf.ones_like(inputs[:,-1,:,:]),1)\n",
    "        batch,h,w,c=inputs.get_shape().as_list()\n",
    "        i=tf.constant(h-1)\n",
    "\n",
    "        def cond(i,mask):\n",
    "            return i > 0\n",
    "        def body(i,mask):\n",
    "            max_value=tf.expand_dims(tf.reduce_max(inputs[:,i:,:,:],1),1)\n",
    "            temp_mask=tf.where(tf.greater(tf.expand_dims(inputs[:,i-1,:,:],1),max_value),ones,zeros)\n",
    "            mask=tf.concat((temp_mask,mask),1)\n",
    "            i = i - 1\n",
    "            return i,mask\n",
    "        _,mask = tf.while_loop(cond, body, [i,mask],shape_invariants= [i.get_shape(), tf.TensorShape([batch,None,w,c])])\n",
    "        return mask*dy\n",
    "\n",
    "    @tf.custom_gradient\n",
    "    def new_grad(x):\n",
    "        def grad(dy):\n",
    "            return backward(x,dy)\n",
    "        return forward(x), grad\n",
    "    return new_grad(inputs)\n",
    "def LeftPool(inputs):\n",
    "    #forward\n",
    "    def forward(inputs):\n",
    "        out=tf.expand_dims(tf.reduce_max(inputs,2),2)\n",
    "        i=tf.constant(1)\n",
    "        batch,h,w,c=inputs.get_shape().as_list()\n",
    "        def cond(i,out):\n",
    "            return i < w\n",
    "        def body(i,out):\n",
    "            d=tf.expand_dims(tf.reduce_max(inputs[:,:,i:,:],2),2)\n",
    "            out=tf.concat((out,d),2)\n",
    "            i = i + 1\n",
    "            return i,out\n",
    "        _,out = tf.while_loop(cond, body, [i,out],shape_invariants= [i.get_shape(), tf.TensorShape([batch,h,None,c])])\n",
    "        return out\n",
    "    #backward\n",
    "    def backward(inputs,dy):\n",
    "        zeros=tf.expand_dims(tf.zeros_like(inputs[:,:,-1,:]),2)\n",
    "        ones=tf.expand_dims(tf.ones_like(inputs[:,:,-1,:]),2)\n",
    "        mask=tf.expand_dims(tf.ones_like(inputs[:,:,-1,:]),2)\n",
    "        batch,h,w,c=inputs.get_shape().as_list()\n",
    "        i=tf.constant(w-1)\n",
    "\n",
    "        def cond(i,mask):\n",
    "            return i > 0\n",
    "        def body(i,mask):\n",
    "            max_value=tf.expand_dims(tf.reduce_max(inputs[:,:,i:,:],2),2)\n",
    "            temp_mask=tf.where(tf.greater(tf.expand_dims(inputs[:,:,i-1,:],2),max_value),ones,zeros)\n",
    "            mask=tf.concat((temp_mask,mask),2)\n",
    "            i = i - 1\n",
    "            return i,mask\n",
    "        _,mask = tf.while_loop(cond, body, [i,mask],shape_invariants= [i.get_shape(), tf.TensorShape([batch,h,None,c])])\n",
    "        return mask*dy\n",
    "\n",
    "    @tf.custom_gradient\n",
    "    def new_grad(x):\n",
    "        def grad(dy):\n",
    "            return backward(x,dy)\n",
    "        return forward(x), grad\n",
    "    return new_grad(inputs)\n",
    "def BottomPool(inputs):\n",
    "    #forward\n",
    "    def forward(inputs):\n",
    "        out=tf.expand_dims(tf.reduce_max(inputs,1),1)\n",
    "        batch,h,w,c=inputs.get_shape().as_list()\n",
    "        i=tf.constant(h-1)\n",
    "\n",
    "        def cond(i,out):\n",
    "            return i > 0\n",
    "        def body(i,out):\n",
    "            d=tf.expand_dims(tf.reduce_max(inputs[:,:i,:,:],1),1)\n",
    "            out=tf.concat((d,out),1)\n",
    "            i = i - 1\n",
    "            return i,out\n",
    "        _,out = tf.while_loop(cond, body, [i,out],shape_invariants= [i.get_shape(), tf.TensorShape([batch,None,w,c])])\n",
    "        return out\n",
    "    #backward\n",
    "    def backward(inputs,dy):\n",
    "        zeros=tf.expand_dims(tf.zeros_like(inputs[:,-1,:,:]),1)\n",
    "        ones=tf.expand_dims(tf.ones_like(inputs[:,-1,:,:]),1)\n",
    "        mask=tf.expand_dims(tf.ones_like(inputs[:,-1,:,:]),1)\n",
    "        batch,h,w,c=inputs.get_shape().as_list()\n",
    "        i=tf.constant(1)\n",
    "\n",
    "        def cond(i,mask):\n",
    "            return i < h\n",
    "        def body(i,mask):\n",
    "            max_value=tf.expand_dims(tf.reduce_max(inputs[:,:i,:,:],1),1)\n",
    "            temp_mask=tf.where(tf.greater(tf.expand_dims(inputs[:,i,:,:],1),max_value),ones,zeros)\n",
    "            mask=tf.concat((mask,temp_mask),1)\n",
    "            i = i + 1\n",
    "            return i,mask\n",
    "        _,mask = tf.while_loop(cond, body, [i,mask],shape_invariants= [i.get_shape(), tf.TensorShape([batch,None,w,c])])\n",
    "        return mask*dy\n",
    "\n",
    "    @tf.custom_gradient\n",
    "    def new_grad(x):\n",
    "        def grad(dy):\n",
    "            return backward(x,dy)\n",
    "        return forward(x), grad\n",
    "    return new_grad(inputs)\n",
    "def RightPool(inputs):\n",
    "    #forward\n",
    "    def forward(inputs):\n",
    "        out=tf.expand_dims(tf.reduce_max(inputs,2),2)\n",
    "        batch,h,w,c=inputs.get_shape().as_list()\n",
    "        i=tf.constant(w-1)\n",
    "\n",
    "        def cond(i,out):\n",
    "            return i > 0\n",
    "        def body(i,out):\n",
    "            d=tf.expand_dims(tf.reduce_max(inputs[:,:,:i,:],2),2)\n",
    "            out=tf.concat((d,out),2)\n",
    "            i = i - 1\n",
    "            return i,out\n",
    "        _,out = tf.while_loop(cond, body, [i,out],shape_invariants= [i.get_shape(), tf.TensorShape([batch,h,None,c])])\n",
    "        return out\n",
    "    #backward\n",
    "    def backward(inputs,dy):\n",
    "        zeros=tf.expand_dims(tf.zeros_like(inputs[:,:,-1,:]),2)\n",
    "        ones=tf.expand_dims(tf.ones_like(inputs[:,:,-1,:]),2)\n",
    "        mask=tf.expand_dims(tf.ones_like(inputs[:,:,-1,:]),2)\n",
    "        batch,h,w,c=inputs.get_shape().as_list()\n",
    "        i=tf.constant(1)\n",
    "\n",
    "        def cond(i,mask):\n",
    "            return i < w\n",
    "        def body(i,mask):\n",
    "            max_value=tf.expand_dims(tf.reduce_max(inputs[:,:,:i,:],2),2)\n",
    "            temp_mask=tf.where(tf.greater(tf.expand_dims(inputs[:,:,i,:],2),max_value),ones,zeros)\n",
    "            mask=tf.concat((mask,temp_mask),2)\n",
    "            i = i + 1\n",
    "            return i,mask\n",
    "        _,mask = tf.while_loop(cond, body, [i,mask],shape_invariants= [i.get_shape(), tf.TensorShape([batch,h,None,c])])\n",
    "        return mask*dy\n",
    "\n",
    "    @tf.custom_gradient\n",
    "    def new_grad(x):\n",
    "        def grad(dy):\n",
    "            return backward(x,dy)\n",
    "        return forward(x), grad\n",
    "    return new_grad(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_wDsMtQs-2fR"
   },
   "source": [
    "Below, post-processing of the detections via non-maximum suppression is defined. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8CRSC87Lp-yS"
   },
   "outputs": [],
   "source": [
    "# forward module\n",
    "\n",
    "def nms(heat):\n",
    "    hmax=tf.nn.max_pool(heat,ksize=[1,3,3,1],strides=[1,1,1,1],padding='SAME')\n",
    "    mask=tf.cast(tf.equal(hmax,heat),tf.float32)\n",
    "    return mask*heat\n",
    "def top_k(heat,k=100):\n",
    "    batch,h,w,c=heat.get_shape().as_list()\n",
    "    heat=tf.reshape(heat,(batch,-1))\n",
    "    k_value,k_index=tf.nn.top_k(heat,k)\n",
    "    k_class=k_index//(h*w)\n",
    "    k_position=k_index%(h*w)\n",
    "    k_y=k_position//w#0 is also a cata\n",
    "    k_x=k_position%w\n",
    "    return k_value,k_position,k_class,k_y,k_x\n",
    "def map_to_vector(feature_map,inds,transpose=True):\n",
    "    #B*128*128*1\n",
    "    #print(feature_map.get_shape().as_list())\n",
    "\n",
    "    #assert tf.shape(inds)[1]==128\n",
    "    def sub_map(value,select):\n",
    "        value=tf.transpose(value,(1,0))\n",
    "        sub_vector=tf.map_fn(fn=lambda x:tf.gather(x,select),elems=value,dtype=tf.float32)\n",
    "        return tf.transpose(sub_vector,(1,0))\n",
    "    if transpose:\n",
    "        assert len(feature_map.get_shape().as_list())==4\n",
    "        inter_vector=tf.reshape(feature_map,(feature_map.get_shape().as_list()[0],-1,feature_map.get_shape().as_list()[-1]))\n",
    "    else:\n",
    "        assert len(feature_map.get_shape().as_list())==3\n",
    "        inter_vector=feature_map\n",
    "    vector=tf.map_fn(fn=lambda p:sub_map(p[0],p[1]),elems=[inter_vector,inds],dtype=tf.float32)\n",
    "    return vector\n",
    "def expand_copy(feature_map,k,inter=False):\n",
    "    feature_map=tf.expand_dims(feature_map,axis=-1)\n",
    "    temp=feature_map\n",
    "    for i in range(k-1):\n",
    "        temp=tf.concat([temp,feature_map],-1)\n",
    "    if inter:\n",
    "        feature_map=tf.transpose(temp,(0,2,1))\n",
    "    else:\n",
    "        feature_map=temp\n",
    "    assert feature_map.get_shape().as_list()[1]==feature_map.get_shape().as_list()[2]\n",
    "    return feature_map\n",
    "\n",
    "def rescale_dets(detections, ratios, borders, sizes):#may be problem\n",
    "    xs, ys = detections[..., 0:4:2], detections[..., 1:4:2]\n",
    "    xs=xs/ ratios[:, 1][:, None, None]#change the shape\n",
    "    ys=ys/ ratios[:, 0][:, None, None]\n",
    "    xs=xs- borders[:, 2][:, None, None]\n",
    "    ys=ys- borders[:, 0][:, None, None]\n",
    "    np.clip(xs, 0, sizes[:, 1][:, None, None], out=xs)\n",
    "    np.clip(ys, 0, sizes[:, 0][:, None, None], out=ys)\n",
    "    detections[..., 0:4:2], detections[..., 1:4:2]=xs, ys\n",
    "    return detections\n",
    "def soft_nms_merge(boxes,sigma=0.5, Nt=0.5, threshold=0.01, method=2, weight_exp=6):\n",
    "    N = boxes.shape[0]\n",
    "    pos = 0\n",
    "    maxscore = 0\n",
    "    maxpos = 0\n",
    "    for i in range(N):\n",
    "        maxscore = boxes[i, 4]\n",
    "        maxpos = i\n",
    "\n",
    "        tx1 = boxes[i,0]\n",
    "        ty1 = boxes[i,1]\n",
    "        tx2 = boxes[i,2]\n",
    "        ty2 = boxes[i,3]\n",
    "        ts = boxes[i,4]\n",
    "\n",
    "        pos = i + 1\n",
    "        # get max box\n",
    "        while pos < N:\n",
    "            if maxscore < boxes[pos, 4]:\n",
    "                maxscore = boxes[pos, 4]\n",
    "                maxpos = pos\n",
    "            pos = pos + 1\n",
    "\n",
    "        # add max box as a detection\n",
    "        boxes[i,0] = boxes[maxpos,0]\n",
    "        boxes[i,1] = boxes[maxpos,1]\n",
    "        boxes[i,2] = boxes[maxpos,2]\n",
    "        boxes[i,3] = boxes[maxpos,3]\n",
    "        boxes[i,4] = boxes[maxpos,4]\n",
    "\n",
    "        mx1 = boxes[i, 0] * boxes[i, 5]\n",
    "        my1 = boxes[i, 1] * boxes[i, 5]\n",
    "        mx2 = boxes[i, 2] * boxes[i, 6]\n",
    "        my2 = boxes[i, 3] * boxes[i, 6]\n",
    "        mts = boxes[i, 5]\n",
    "        mbs = boxes[i, 6]\n",
    "\n",
    "        # swap ith box with position of max box\n",
    "        boxes[maxpos,0] = tx1\n",
    "        boxes[maxpos,1] = ty1\n",
    "        boxes[maxpos,2] = tx2\n",
    "        boxes[maxpos,3] = ty2\n",
    "        boxes[maxpos,4] = ts\n",
    "\n",
    "        tx1 = boxes[i,0]\n",
    "        ty1 = boxes[i,1]\n",
    "        tx2 = boxes[i,2]\n",
    "        ty2 = boxes[i,3]\n",
    "        ts = boxes[i,4]\n",
    "\n",
    "        pos = i + 1\n",
    "        # NMS iterations, note that N changes if detection boxes fall below threshold\n",
    "        while pos < N:\n",
    "            x1 = boxes[pos, 0]\n",
    "            y1 = boxes[pos, 1]\n",
    "            x2 = boxes[pos, 2]\n",
    "            y2 = boxes[pos, 3]\n",
    "            s = boxes[pos, 4]\n",
    "\n",
    "            area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "            iw = (min(tx2, x2) - max(tx1, x1) + 1)\n",
    "            if iw > 0:\n",
    "                ih = (min(ty2, y2) - max(ty1, y1) + 1)\n",
    "                if ih > 0:\n",
    "                    ua = float((tx2 - tx1 + 1) * (ty2 - ty1 + 1) + area - iw * ih)\n",
    "                    ov = iw * ih / ua #iou between max box and detection box\n",
    "\n",
    "                    if method == 1: # linear\n",
    "                        if ov > Nt:\n",
    "                            weight = 1 - ov\n",
    "                        else:\n",
    "                            weight = 1\n",
    "                    elif method == 2: # gaussian\n",
    "                        weight = np.exp(-(ov * ov)/sigma)\n",
    "                    else: # original NMS\n",
    "                        if ov > Nt:\n",
    "                            weight = 0\n",
    "                        else:\n",
    "                            weight = 1\n",
    "\n",
    "                    mw  = (1 - weight) ** weight_exp\n",
    "                    mx1 = mx1 + boxes[pos, 0] * boxes[pos, 5] * mw\n",
    "                    my1 = my1 + boxes[pos, 1] * boxes[pos, 5] * mw\n",
    "                    mx2 = mx2 + boxes[pos, 2] * boxes[pos, 6] * mw\n",
    "                    my2 = my2 + boxes[pos, 3] * boxes[pos, 6] * mw\n",
    "                    mts = mts + boxes[pos, 5] * mw\n",
    "                    mbs = mbs + boxes[pos, 6] * mw\n",
    "\n",
    "                    boxes[pos, 4] = weight*boxes[pos, 4]\n",
    "\n",
    "                    # if box score falls below threshold, discard the box by swapping with last box\n",
    "                    # update N\n",
    "                    if boxes[pos, 4] < threshold:\n",
    "                        boxes[pos,0] = boxes[N-1, 0]\n",
    "                        boxes[pos,1] = boxes[N-1, 1]\n",
    "                        boxes[pos,2] = boxes[N-1, 2]\n",
    "                        boxes[pos,3] = boxes[N-1, 3]\n",
    "                        boxes[pos,4] = boxes[N-1, 4]\n",
    "                        N = N - 1\n",
    "                        pos = pos - 1\n",
    "\n",
    "            pos = pos + 1\n",
    "\n",
    "        boxes[i, 0] = mx1 / mts\n",
    "        boxes[i, 1] = my1 / mts\n",
    "        boxes[i, 2] = mx2 / mbs\n",
    "        boxes[i, 3] = my2 / mbs\n",
    "\n",
    "    #keep = [i for i in range(N)]\n",
    "    return boxes[0:N,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uzgakQpe3Mzh"
   },
   "source": [
    "Below, the loss functions for the net are defined.\n",
    "\n",
    "One aspect of the loss is the detection of the corners. In particular, the top left and the bottom right corners are detected. These are represented as two sets of heatmaps, one for each corner. Each set consists of 80 channels (corresponding to the number of categories) and has the dimensions 128x128 (=resolution). During training, the negative locations of the corner within a set radius of the ground truth positive location are penalized, represented as a 2D Gaussian. This is implemented as the *focal loss*. \n",
    "Furthermore, in order to get tighter bounding boxes, the offsets of the ground truth corner positions are also predicted. To learn these, the *smoothed L1 loss* is applied as the `offset_loss`. \n",
    "Finally, the `tag_loss` is used to learn the grouping of the corners of the same object. The goal is to minimize the distance between the embeddings of the corners of the same object, and maximize the distance for different objects. Specifically, the former component of the loss is called the *pull loss*, and the latter the *push loss*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nYC0O9LBqYcJ"
   },
   "outputs": [],
   "source": [
    "# loss module\n",
    "\n",
    "# loss for learning the ground truth location of the corner\n",
    "def focal_loss(preds,gt):\n",
    "    print(gt.get_shape().as_list())\n",
    "    zeros=tf.zeros_like(gt)\n",
    "    ones=tf.ones_like(gt)\n",
    "    num_pos=tf.reduce_sum(tf.where(tf.equal(gt,1),ones,zeros))\n",
    "    loss=0\n",
    "    #loss=tf.reduce_mean(tf.log(preds))\n",
    "    for pre in preds:\n",
    "        pos_weight=tf.where(tf.equal(gt,1),ones-pre,zeros)\n",
    "        neg_weight=tf.where(tf.less(gt,1),pre,zeros)\n",
    "        pos_loss=tf.reduce_sum(tf.log(pre) * tf.pow(pos_weight,2))\n",
    "        neg_loss=tf.reduce_sum(tf.pow((1-gt),4)*tf.pow(neg_weight,2)*tf.log((1-pre)))\n",
    "        loss=loss-(pos_loss+neg_loss)/(num_pos+tf.convert_to_tensor(1e-4))\n",
    "    return loss\n",
    "\n",
    "# loss for learning the grouping of the corners per object\n",
    "def tag_loss(tag0, tag1, mask):\n",
    "    #pull\n",
    "    print(tag0.get_shape().as_list())\n",
    "    tag0=tf.squeeze(tag0,axis=-1)\n",
    "    tag1=tf.squeeze(tag1,axis=-1)\n",
    "    zeros=tf.zeros_like(mask)\n",
    "    ones=tf.ones_like(mask)\n",
    "    num  = tf.reduce_sum(mask)\n",
    "\n",
    "\n",
    "    tag_mean = (tag0 + tag1) / 2\n",
    "\n",
    "    tag0 = tf.pow((tag0 - tag_mean) , 2) / (num + tf.convert_to_tensor(1e-4))\n",
    "    #tag0_mask=tf.where(tf.equal(mask,1),ones,zeros)\n",
    "    tag0 = tf.reduce_sum(tag0*mask)\n",
    "\n",
    "    tag1 = tf.pow((tag1 - tag_mean), 2) / (num + tf.convert_to_tensor(1e-4))\n",
    "    #tag1_mask=tf.where(tf.equal(mask,1),ones,zeros)\n",
    "    tag1 = tf.reduce_sum(tag1*mask)\n",
    "    pull = tag0 + tag1\n",
    "    #push\n",
    "    dist_mask=tf.reshape(mask,(tf.shape(mask)[0],1,tf.shape(mask)[1]))+tf.reshape(mask,(tf.shape(mask)[0],tf.shape(mask)[1],1))\n",
    "    dist_zeros=tf.zeros_like(dist_mask)\n",
    "    dist_ones=tf.ones_like(dist_mask)\n",
    "    dist_mask=tf.where(tf.equal(dist_mask,2),dist_ones,dist_zeros)\n",
    "    num2=num*(num-1)\n",
    "    dist=tf.reshape(tag_mean,(tf.shape(tag_mean)[0],1,tf.shape(tag_mean)[1]))-tf.reshape(tag_mean,(tf.shape(tag_mean)[0],tf.shape(tag_mean)[1],1))\n",
    "    #dist=-tf.pow(dist,2)\n",
    "    dist=1-tf.abs(dist)\n",
    "    dist=tf.nn.relu(dist)\n",
    "    dist=dist-1 / (num + tf.convert_to_tensor(1e-4))\n",
    "    dist=dist / (num2 + tf.convert_to_tensor(1e-4))\n",
    "    dist=tf.multiply(dist_mask,dist)\n",
    "    push=tf.reduce_sum(dist)\n",
    "    return pull, push\n",
    "\n",
    "# loss for learning the offset of the ground truth position of the corner\n",
    "def offset_loss(offset, gt_offset, mask):\n",
    "    num  = tf.reduce_sum(mask)\n",
    "    mask = tf.stack((mask,mask),-1)\n",
    "    offset_loss = smooth_l1_loss(offset, gt_offset)\n",
    "    offset_loss = offset_loss / (num + tf.convert_to_tensor(1e-4))\n",
    "    offset_loss=tf.reduce_sum(tf.multiply(offset_loss,mask))\n",
    "    return offset_loss\n",
    "def smooth_l1_loss(pred,targets,sigma=1):\n",
    "    # diff = pred -targets\n",
    "    # abs_diff = tf.abs(diff)\n",
    "    # smoothL1_sign =tf.to_float(tf.less(abs_diff, 1))\n",
    "    # loss = tf.pow(diff, 2) * 0.5 * smoothL1_sign + (abs_diff - 0.5) * (1. - smoothL1_sign)\n",
    "    # return loss\n",
    "    sigma2 = sigma * sigma\n",
    "\n",
    "    diff = tf.subtract(pred, targets)\n",
    "\n",
    "    smooth_l1_sign = tf.cast(tf.less(tf.abs(diff), 1.0 / sigma2), tf.float32)\n",
    "    smooth_l1_option1 = tf.multiply(tf.multiply(diff, diff), 0.5 * sigma2)\n",
    "    smooth_l1_option2 = tf.subtract(tf.abs(diff), 0.5 / sigma2)\n",
    "    smooth_l1_result = tf.add(tf.multiply(smooth_l1_option1, smooth_l1_sign),tf.multiply(smooth_l1_option2, tf.abs(tf.subtract(smooth_l1_sign, 1.0))))\n",
    "    return smooth_l1_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RKhJawCSrxEx"
   },
   "source": [
    "Below, helper modules for importing and preparing the data are defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oecYmjENtIsL"
   },
   "outputs": [],
   "source": [
    "# initialize data\n",
    "\n",
    "class MSCOCO():\n",
    "    def __init__(self,split):\n",
    "        data_dir   = cfg.data_dir\n",
    "        result_dir = cfg.result_dir\n",
    "        cache_dir  = cfg.cache_dir\n",
    "\n",
    "        self._split = split\n",
    "       # for example purposes, due to memory limitations we only import one dataset\n",
    "        self._dataset = {\n",
    "            \"trainval\": \"val2017\",\n",
    "            \"minival\": \"val2017\",\n",
    "            \"testdev\": \"val2017\"\n",
    "        }[self._split]\n",
    "\n",
    "        self._coco_dir = os.path.join(data_dir, \"cocoapi\") # originally just \"coco\"\n",
    "\n",
    "      # get annotations location\n",
    "        self._label_dir  = os.path.join(self._coco_dir, \"annotations\")\n",
    "        self._label_file = os.path.join(self._label_dir, \"instances_{}.json\")\n",
    "        self._label_file = self._label_file.format(self._dataset)\n",
    "        print(self._label_file)\n",
    "\n",
    "        self._image_dir  = os.path.join(self._coco_dir, \"images\", self._dataset)\n",
    "        self._image_file = os.path.join(self._image_dir, \"{}\")\n",
    "\n",
    "        self._data = \"coco\"\n",
    "        self._mean = np.array([0.40789654, 0.44719302, 0.47026115], dtype=np.float32)\n",
    "        self._std  = np.array([0.28863828, 0.27408164, 0.27809835], dtype=np.float32)\n",
    "        self._eig_val = np.array([0.2141788, 0.01817699, 0.00341571], dtype=np.float32)\n",
    "        self._eig_vec = np.array([\n",
    "            [-0.58752847, -0.69563484, 0.41340352],\n",
    "            [-0.5832747, 0.00994535, -0.81221408],\n",
    "            [-0.56089297, 0.71832671, 0.41158938]\n",
    "        ], dtype=np.float32)\n",
    "\n",
    "        self._cat_ids = [\n",
    "            1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13,\n",
    "            14, 15, 16, 17, 18, 19, 20, 21, 22, 23,\n",
    "            24, 25, 27, 28, 31, 32, 33, 34, 35, 36,\n",
    "            37, 38, 39, 40, 41, 42, 43, 44, 46, 47,\n",
    "            48, 49, 50, 51, 52, 53, 54, 55, 56, 57,\n",
    "            58, 59, 60, 61, 62, 63, 64, 65, 67, 70,\n",
    "            72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
    "            82, 84, 85, 86, 87, 88, 89, 90\n",
    "        ]\n",
    "        self._classes = {\n",
    "            ind + 1: cat_id for ind, cat_id in enumerate(self._cat_ids)\n",
    "        }\n",
    "        self._coco_to_class_map = {\n",
    "            value: key for key, value in self._classes.items()\n",
    "        }\n",
    "# cache loaded dataset\n",
    "        self._cache_file = os.path.join(cache_dir, \"coco_{}.pkl\".format(self._dataset))\n",
    "        self._load_data()\n",
    "        self._db_inds = np.arange(len(self._image_ids))\n",
    "\n",
    "        self._load_coco_data()\n",
    "\n",
    "\n",
    "    def _load_data(self):\n",
    "        print(\"loading from cache file: {}\".format(self._cache_file))\n",
    "        if not os.path.exists(self._cache_file):\n",
    "            print(\"No cache file found...\")\n",
    "            self._extract_data()\n",
    "            with open(self._cache_file, \"wb\") as f:\n",
    "                pickle.dump([self._detections, self._image_ids], f)#self._image_ids is img's name.self._detections is {name:box and cat([N,5])}\n",
    "        else:\n",
    "            with open(self._cache_file, \"rb\") as f:\n",
    "                self._detections, self._image_ids = pickle.load(f)\n",
    "        \n",
    "# load annotations\n",
    "    def _load_coco_data(self):\n",
    "        self._coco = COCO(self._label_file)\n",
    "        with open(self._label_file, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        coco_ids = self._coco.getImgIds()\n",
    "        eval_ids = {\n",
    "            self._coco.loadImgs(coco_id)[0][\"file_name\"]: coco_id\n",
    "            for coco_id in coco_ids\n",
    "        }\n",
    "# get categories\n",
    "        self._coco_categories = data[\"categories\"]\n",
    "        self._coco_eval_ids   = eval_ids\n",
    "\n",
    "    def class_name(self, cid):\n",
    "        cat_id = self._classes[cid]\n",
    "        cat    = self._coco.loadCats([cat_id])[0]\n",
    "        return cat[\"name\"]\n",
    "\n",
    "    def _extract_data(self):\n",
    "        self._coco    = COCO(self._label_file)\n",
    "        self._cat_ids = self._coco.getCatIds()\n",
    "\n",
    "        coco_image_ids = self._coco.getImgIds()\n",
    "\n",
    "        self._image_ids = [\n",
    "            self._coco.loadImgs(img_id)[0][\"file_name\"]\n",
    "            for img_id in coco_image_ids\n",
    "        ]\n",
    "        self._detections = {}\n",
    "        for ind, (coco_image_id, image_id) in enumerate(tqdm(zip(coco_image_ids, self._image_ids))):\n",
    "            image      = self._coco.loadImgs(coco_image_id)[0]\n",
    "            bboxes     = []\n",
    "            categories = []\n",
    "# map categories and bounding boxes to images\n",
    "            for cat_id in self._cat_ids:\n",
    "                annotation_ids = self._coco.getAnnIds(imgIds=image[\"id\"], catIds=cat_id)\n",
    "                annotations    = self._coco.loadAnns(annotation_ids)\n",
    "                category       = self._coco_to_class_map[cat_id]\n",
    "                for annotation in annotations:\n",
    "                    bbox = np.array(annotation[\"bbox\"])\n",
    "                    bbox[[2, 3]] += bbox[[0, 1]]\n",
    "                    bboxes.append(bbox)\n",
    "\n",
    "                    categories.append(category)\n",
    "\n",
    "            bboxes     = np.array(bboxes, dtype=float)\n",
    "            categories = np.array(categories, dtype=float)\n",
    "            if bboxes.size == 0 or categories.size == 0:\n",
    "                self._detections[image_id] = np.zeros((0, 5), dtype=np.float32)\n",
    "            else:\n",
    "                self._detections[image_id] = np.hstack((bboxes, categories[:, None]))#each image's all boxes and box's cat [N,4]\n",
    "  # helpers              \n",
    "    def get_all_img(self):\n",
    "        return self._image_ids\n",
    "    def read_img(self,img_name):\n",
    "        print(img_name)\n",
    "        img_path =self._image_file.format(bytes.decode(img_name)) # .encode() img_name\n",
    "        img=cv2.imread(img_path)\n",
    "        return img.astype(np.float32)\n",
    "    def detections(self, img_name):\n",
    "        detections = self._detections[bytes.decode(img_name)]\n",
    "\n",
    "        return detections.astype(float).copy()\n",
    "\n",
    "    def _to_float(self, x):\n",
    "        return float(\"{:.2f}\".format(x))\n",
    "\n",
    "    def convert_to_coco(self, all_bboxes):\n",
    "        detections = []\n",
    "        for image_id in all_bboxes:\n",
    "            coco_id = self._coco_eval_ids[image_id]\n",
    "            for cls_ind in all_bboxes[image_id]:\n",
    "                category_id = self._classes[cls_ind]\n",
    "                for bbox in all_bboxes[image_id][cls_ind]:\n",
    "                    bbox[2] -= bbox[0]\n",
    "                    bbox[3] -= bbox[1]\n",
    "\n",
    "                    score = bbox[4]\n",
    "                    bbox  = list(map(self._to_float, bbox[0:4]))\n",
    "\n",
    "                    detection = {\n",
    "                        \"image_id\": coco_id,\n",
    "                        \"category_id\": category_id,\n",
    "                        \"bbox\": bbox,\n",
    "                        \"score\": float(\"{:.2f}\".format(score))\n",
    "                    }\n",
    "\n",
    "                    detections.append(detection)\n",
    "        return detections\n",
    "# evaluate predicted bboxes on testdata \n",
    "    def evaluate(self, result_json, cls_ids, image_ids, gt_json=None):\n",
    "        if self._split == \"testdev\":\n",
    "            return None\n",
    "\n",
    "        coco = self._coco if gt_json is None else COCO(gt_json)\n",
    "\n",
    "        eval_ids = [self._coco_eval_ids[image_id] for image_id in image_ids]\n",
    "        cat_ids  = [self._classes[cls_id] for cls_id in cls_ids]\n",
    "\n",
    "        coco_dets = coco.loadRes(result_json)\n",
    "        coco_eval = COCOeval(coco, coco_dets, \"bbox\")\n",
    "        coco_eval.params.imgIds = eval_ids\n",
    "        coco_eval.params.catIds = cat_ids\n",
    "        coco_eval.evaluate()\n",
    "        coco_eval.accumulate()\n",
    "        coco_eval.summarize()\n",
    "        return coco_eval.stats[0], coco_eval.stats[12:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "He7bCUIYh9ck"
   },
   "source": [
    "Here, possible transformations of the images for improving performance are defined. The 2D Gaussian used in the corner localization is also defined here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uMU-IfsxJ6Kt"
   },
   "outputs": [],
   "source": [
    "# transformation\n",
    "def full_image_crop(image, detections):\n",
    "    detections    = detections.copy()\n",
    "    height, width = image.shape[0:2]\n",
    "\n",
    "    max_hw = max(height, width)\n",
    "    center = [height // 2, width // 2]\n",
    "    size   = [max_hw, max_hw]\n",
    "\n",
    "    image, border, offset = crop_image(image, center, size)\n",
    "    detections[:, 0:4:2] += border[2]\n",
    "    detections[:, 1:4:2] += border[0]\n",
    "    return image, detections\n",
    "\n",
    "def resize_image(image, detections, size):\n",
    "    detections    = detections.copy()\n",
    "    height, width = image.shape[0:2]\n",
    "    new_height, new_width = size\n",
    "\n",
    "    image = cv2.resize(image, (new_width, new_height))\n",
    "\n",
    "    height_ratio = new_height / height\n",
    "    width_ratio  = new_width  / width\n",
    "    detections[:, 0:4:2] *= width_ratio\n",
    "    detections[:, 1:4:2] *= height_ratio\n",
    "    return image, detections\n",
    "\n",
    "def clip_detections(image, detections):\n",
    "    detections    = detections.copy()\n",
    "    height, width = image.shape[0:2]\n",
    "\n",
    "    detections[:, 0:4:2] = np.clip(detections[:, 0:4:2], 0, width - 1)\n",
    "    detections[:, 1:4:2] = np.clip(detections[:, 1:4:2], 0, height - 1)\n",
    "    keep_inds  = ((detections[:, 2] - detections[:, 0]) > 0) & \\\n",
    "                 ((detections[:, 3] - detections[:, 1]) > 0)\n",
    "    detections = detections[keep_inds]\n",
    "    return detections\n",
    "\n",
    "# define heatmap of negative corner location penalties  \n",
    "def gaussian2D(shape, sigma=1):\n",
    "    m, n = [(ss - 1.) / 2. for ss in shape]\n",
    "    y, x = np.ogrid[-m:m+1,-n:n+1]\n",
    "\n",
    "    h = np.exp(-(x * x + y * y) / (2 * sigma * sigma))\n",
    "    h[h < np.finfo(h.dtype).eps * h.max()] = 0\n",
    "    return h\n",
    "\n",
    "def draw_gaussian(heatmap, center, radius, k=1):\n",
    "    diameter = 2 * radius + 1\n",
    "    gaussian = gaussian2D((diameter, diameter), sigma=diameter / 6)\n",
    "\n",
    "    x, y = center\n",
    "\n",
    "    height, width = heatmap.shape[0:2]\n",
    "\n",
    "    left, right = min(x, radius), min(width - x, radius + 1)\n",
    "    top, bottom = min(y, radius), min(height - y, radius + 1)\n",
    "\n",
    "    masked_heatmap  = heatmap[y - top:y + bottom, x - left:x + right]\n",
    "    masked_gaussian = gaussian[radius - top:radius + bottom, radius - left:radius + right]\n",
    "    np.maximum(masked_heatmap, masked_gaussian * k, out=masked_heatmap)\n",
    "\n",
    "def gaussian_radius(det_size, min_overlap):\n",
    "    height, width = det_size\n",
    "\n",
    "    a1  = 1\n",
    "    b1  = (height + width)\n",
    "    c1  = width * height * (1 - min_overlap) / (1 + min_overlap)\n",
    "    sq1 = np.sqrt(b1 ** 2 - 4 * a1 * c1)\n",
    "    r1  = (b1 + sq1) / 2\n",
    "\n",
    "    a2  = 4\n",
    "    b2  = 2 * (height + width)\n",
    "    c2  = (1 - min_overlap) * width * height\n",
    "    sq2 = np.sqrt(b2 ** 2 - 4 * a2 * c2)\n",
    "    r2  = (b2 + sq2) / 2\n",
    "\n",
    "    a3  = 4 * min_overlap\n",
    "    b3  = -2 * min_overlap * (height + width)\n",
    "    c3  = (min_overlap - 1) * width * height\n",
    "    sq3 = np.sqrt(b3 ** 2 - 4 * a3 * c3)\n",
    "    r3  = (b3 + sq3) / 2\n",
    "    return min(r1, r2, r3)\n",
    "\n",
    "def _get_border(border, size):\n",
    "    i = 1\n",
    "    while size - border // i <= border // i:\n",
    "        i *= 2\n",
    "    return border // i\n",
    "\n",
    "def random_crop(image, detections, random_scales, view_size, border=64):\n",
    "    view_height, view_width   = view_size\n",
    "    image_height, image_width = image.shape[0:2]\n",
    "\n",
    "    scale  = np.random.choice(random_scales)\n",
    "    height = int(view_height * scale)\n",
    "    width  = int(view_width  * scale)\n",
    "\n",
    "    cropped_image = np.zeros((height, width, 3), dtype=image.dtype)\n",
    "\n",
    "    w_border = _get_border(border, image_width)\n",
    "    h_border = _get_border(border, image_height)\n",
    "\n",
    "    ctx = np.random.randint(low=w_border, high=image_width - w_border)\n",
    "    cty = np.random.randint(low=h_border, high=image_height - h_border)\n",
    "\n",
    "    x0, x1 = max(ctx - width // 2, 0),  min(ctx + width // 2, image_width)\n",
    "    y0, y1 = max(cty - height // 2, 0), min(cty + height // 2, image_height)\n",
    "\n",
    "    left_w, right_w = ctx - x0, x1 - ctx\n",
    "    top_h, bottom_h = cty - y0, y1 - cty\n",
    "\n",
    "    # crop image\n",
    "    cropped_ctx, cropped_cty = width // 2, height // 2\n",
    "    x_slice = slice(cropped_ctx - left_w, cropped_ctx + right_w)\n",
    "    y_slice = slice(cropped_cty - top_h, cropped_cty + bottom_h)\n",
    "    cropped_image[y_slice, x_slice, :] = image[y0:y1, x0:x1, :]\n",
    "\n",
    "    # crop detections\n",
    "    cropped_detections = detections.copy()\n",
    "    cropped_detections[:, 0:4:2] -= x0\n",
    "    cropped_detections[:, 1:4:2] -= y0\n",
    "    cropped_detections[:, 0:4:2] += cropped_ctx - left_w\n",
    "    cropped_detections[:, 1:4:2] += cropped_cty - top_h\n",
    "\n",
    "    return cropped_image, cropped_detections\n",
    "\n",
    "# add perturbations to images to improve performance    \n",
    "def grayscale(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "def normalize_(image, mean, std):\n",
    "    image -= mean\n",
    "    image /= std\n",
    "\n",
    "def lighting_(data_rng, image, alphastd, eigval, eigvec):\n",
    "    alpha = data_rng.normal(scale=alphastd, size=(3, ))\n",
    "    image += np.dot(eigvec, eigval * alpha)\n",
    "\n",
    "def blend_(alpha, image1, image2):\n",
    "    image1 *= alpha\n",
    "    image2 *= (1 - alpha)\n",
    "    image1 += image2\n",
    "\n",
    "def saturation_(data_rng, image, gs, gs_mean, var):\n",
    "    alpha = 1. + data_rng.uniform(low=-var, high=var)\n",
    "    blend_(alpha, image, gs[:, :, None])\n",
    "\n",
    "def brightness_(data_rng, image, gs, gs_mean, var):\n",
    "    alpha = 1. + data_rng.uniform(low=-var, high=var)\n",
    "    image *= alpha\n",
    "\n",
    "def contrast_(data_rng, image, gs, gs_mean, var):\n",
    "    alpha = 1. + data_rng.uniform(low=-var, high=var)\n",
    "    blend_(alpha, image, gs_mean)\n",
    "\n",
    "def color_jittering_(data_rng, image):\n",
    "    functions = [brightness_, contrast_, saturation_]\n",
    "    random.shuffle(functions)\n",
    "\n",
    "    gs = grayscale(image)\n",
    "    gs_mean = gs.mean()\n",
    "    for f in functions:\n",
    "        f(data_rng, image, gs, gs_mean, 0.4)\n",
    "def crop_image(image, center, size):\n",
    "    cty, ctx            = center\n",
    "    height, width       = size\n",
    "    im_height, im_width = image.shape[0:2]\n",
    "    cropped_image       = np.zeros((height, width, 3), dtype=image.dtype)\n",
    "\n",
    "    x0, x1 = max(0, ctx - width // 2), min(ctx + width // 2, im_width)\n",
    "    y0, y1 = max(0, cty - height // 2), min(cty + height // 2, im_height)\n",
    "\n",
    "    left, right = ctx - x0, x1 - ctx\n",
    "    top, bottom = cty - y0, y1 - cty\n",
    "\n",
    "    cropped_cty, cropped_ctx = height // 2, width // 2\n",
    "    y_slice = slice(cropped_cty - top, cropped_cty + bottom)\n",
    "    x_slice = slice(cropped_ctx - left, cropped_ctx + right)\n",
    "    cropped_image[y_slice, x_slice, :] = image[y0:y1, x0:x1, :]\n",
    "\n",
    "    border = np.array([\n",
    "       cropped_cty - top,\n",
    "       cropped_cty + bottom,\n",
    "       cropped_ctx - left,\n",
    "       cropped_ctx + right\n",
    "    ], dtype=np.float32)\n",
    "\n",
    "    offset = np.array([\n",
    "        cty - height // 2,\n",
    "        ctx - width  // 2\n",
    "    ])\n",
    "\n",
    "    return cropped_image, border, offset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aSxYpsIfHeT2"
   },
   "source": [
    "Below, the data is loaded and batched. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KaqS8a-Pqos_",
    "outputId": "78334750-6655-4ae5-8557-f6027dcae9f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/cocoapi/annotations/instances_val2017.json\n",
      "loading from cache file: ./cache/coco_val2017.pkl\n",
      "loading annotations into memory...\n",
      "Done (t=1.11s)\n",
      "creating index...\n",
      "index created!\n",
      "True\n",
      "WARNING:tensorflow:From <ipython-input-24-fb62dc3733e4>:116: slice_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(tuple(tensor_list)).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/input.py:373: range_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.range(limit).shuffle(limit).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/input.py:319: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/input.py:189: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/input.py:198: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/input.py:198: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From <ipython-input-24-fb62dc3733e4>:112: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "WARNING:tensorflow:From <ipython-input-24-fb62dc3733e4>:124: shuffle_batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.shuffle(min_after_dequeue).batch(batch_size)`.\n",
      "WARNING:tensorflow:From <ipython-input-24-fb62dc3733e4>:133: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "b'000000355677.jpg'\n",
      "b'000000268831.jpg'\n",
      "b'000000126226.jpg'\n",
      "b'000000039670.jpg'\n",
      "b'000000479448.jpg'\n",
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 68  0  0  0 77  0\n",
      "  0  0  0  0 40  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0]\n",
      "b'000000402519.jpg'\n",
      "b'000000017905.jpg'\n",
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0 63  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0]\n",
      "b'000000501368.jpg'\n",
      "b'000000319721.jpg'\n",
      "b'000000322724.jpg'\n",
      "b'000000576955.jpg'\n",
      "b'000000025593.jpg'\n",
      "b'000000396338.jpg'\n",
      "b'000000060347.jpg'\n",
      "b'000000262938.jpg'\n",
      "b'000000551794.jpg'\n",
      "b'000000231549.jpg'\n",
      "b'000000220310.jpg'\n",
      "b'000000250282.jpg'\n",
      "b'000000237984.jpg'\n",
      "b'000000552612.jpg'\n",
      "b'000000079034.jpg'\n",
      "b'000000370208.jpg'\n",
      "b'000000450075.jpg'\n",
      "b'000000515025.jpg'\n",
      "b'000000479126.jpg'\n",
      "b'000000474854.jpg'\n",
      "b'000000223738.jpg'\n",
      "b'000000315492.jpg'\n",
      "b'000000044590.jpg'\n",
      "b'000000476415.jpg'\n",
      "b'000000108864.jpg'\n",
      "b'000000427500.jpg'\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]b'000000402433.jpg'\n",
      "\n",
      "b'000000326248.jpg'\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  60   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0  17   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0 116   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0]\n",
      "b'000000203317.jpg'\n",
      "b'000000546976.jpg'\n",
      "b'000000356169.jpg'\n",
      "b'000000324614.jpg'\n",
      "b'000000559842.jpg'\n",
      "b'000000473869.jpg'\n",
      "b'000000159684.jpg'[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  19\n",
      "   0  31  67   0  80   0  11   0   0  66  52  82 117   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0]\n",
      "\n",
      "b'000000222825.jpg'\n",
      "[  0   0   0   0   0   0   0   0 116   0   0   0   0   0   0  38   0   0\n",
      "   0   0   0   0   0   0  50   0   0   0   0   0   0   0   0   0  98   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0 115   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0]\n",
      "b'000000036936.jpg'\n",
      "b'000000050331.jpg'\n",
      "b'000000125129.jpg'\n",
      "b'000000282296.jpg'\n",
      "b'000000263796.jpg'\n",
      "b'000000550797.jpg'\n",
      "b'000000194471.jpg'\n",
      "b'000000236784.jpg'\n",
      "b'000000497867.jpg'\n",
      "b'000000270297.jpg'\n",
      "b'000000007816.jpg'\n",
      "b'000000248980.jpg'\n",
      "b'000000511999.jpg'\n",
      "b'000000235252.jpg'\n",
      "b'000000570736.jpg'\n",
      "b'000000297698.jpg'\n",
      "b'000000250127.jpg'\n",
      "b'000000465430.jpg'\n",
      "b'000000007574.jpg'\n",
      "b'000000528862.jpg'\n",
      "b'000000578545.jpg'\n",
      "b'000000369757.jpg'\n",
      "b'000000384661.jpg'\n",
      "b'000000177893.jpg'\n",
      "[ 0  0  0  0  0  0  0  0  0  0  0 46  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0 21  0  0  0 85  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      " 48  0  0  0  0  0  0  0  0  0  0  0  0  5  0  0 11 35  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0]b'000000312278.jpg'\n",
      "\n",
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0 34  0 68  0 75  0 55  0  0 44\n",
      "  0  0  0  0  0  0 48  0  0  0  0  0 48  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0]\n",
      "b'000000547144.jpg'\n",
      "b'000000430973.jpg'\n",
      "b'000000301421.jpg'\n",
      "b'000000522713.jpg'\n",
      "b'000000172946.jpg'\n",
      "b'000000274411.jpg'\n",
      "b'000000308394.jpg'\n",
      "b'000000122927.jpg'\n",
      "b'000000171382.jpg'\n",
      "b'000000383289.jpg'\n",
      "b'000000214200.jpg'\n",
      "b'000000495448.jpg'\n",
      "b'000000163314.jpg'\n",
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 43  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0]\n",
      "b'000000424551.jpg'\n",
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0 11  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0]\n",
      "b'000000147205.jpg'\n",
      "b'000000358923.jpg'\n",
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  6  0  0  0  0  0  0  0  0  0\n",
      " 46 53  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0]\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0 106  91   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0]\n",
      "b'000000085682.jpg'\n",
      "b'000000236592.jpg'\n",
      "b'000000190756.jpg'\n",
      "b'000000022479.jpg'\n",
      "b'000000399764.jpg'\n",
      "b'000000496722.jpg'\n",
      "b'000000133087.jpg'\n",
      "b'000000452321.jpg'\n",
      "b'000000516708.jpg'\n",
      "b'000000261116.jpg'\n",
      "b'000000555050.jpg'\n",
      "b'000000460927.jpg'\n",
      "b'000000108495.jpg'\n",
      "b'000000493442.jpg'\n",
      "b'000000157756.jpg'\n",
      "b'000000543047.jpg'\n",
      "b'000000453341.jpg'\n",
      "b'000000341719.jpg'\n",
      "b'000000487583.jpg'\n",
      "b'000000424545.jpg'\n",
      "b'000000091406.jpg'\n",
      "b'000000232649.jpg'\n",
      "b'000000306136.jpg'\n",
      "b'000000212453.jpg'\n",
      "b'000000027768.jpg'\n",
      "b'000000123213.jpg'\n",
      "b'000000119641.jpg'\n",
      "b'000000226147.jpg'\n",
      "b'000000293200.jpg'\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "b'000000509260.jpg'\n",
      "b'000000439994.jpg'\n",
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 89  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0]\n",
      "b'000000083113.jpg'\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0 105   0  97   0\n",
      "   0   0   0   0   0   0   0   0   0  28   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0]\n",
      "b'000000154431.jpg'\n",
      "b'000000267670.jpg'\n",
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 16  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0]\n",
      "b'000000478393.jpg'\n",
      "b'000000136600.jpg'\n",
      "b'000000312237.jpg'\n",
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0 92  0 27  0 32 34  0  0  0 60\n",
      "  0  0  0  0  0 74  0  0 55  0  0  0  0 67 58  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0]\n",
      "b'000000304396.jpg'\n",
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0 83  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0 95  0  0  0]\n",
      "b'000000433980.jpg'\n",
      "b'000000225532.jpg'\n",
      "b'000000477689.jpg'\n",
      "b'000000144003.jpg'\n",
      "b'000000279887.jpg'\n",
      "[16  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0]\n",
      "b'000000002587.jpg'\n",
      "b'000000068078.jpg'\n",
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      " 43  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0]b'000000327617.jpg'\n",
      "\n",
      "b'000000302536.jpg'\n",
      "b'000000472678.jpg'\n",
      "b'000000316015.jpg'\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "b'000000425390.jpg'\n",
      "[ 0  0  0  0  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 29  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0 50  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0]\n",
      "b'000000186282.jpg'\n",
      "b'000000095069.jpg'\n",
      "b'000000007784.jpg'\n",
      "b'000000205647.jpg'\n",
      "[45  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0]\n",
      "[ 0  0  0  0  0  0  0  0 18  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0]\n",
      "b'000000437239.jpg'\n",
      "b'000000186345.jpg'\n"
     ]
    }
   ],
   "source": [
    "# get data\n",
    "class Image_data():\n",
    "    def __init__(self,split):\n",
    "        self.coco=MSCOCO(split)\n",
    "        self.data_rng   = cfg.data_rng\n",
    "        self.num_image  = len(self.coco.get_all_img())\n",
    "        self.categories   = cfg.categories\n",
    "        self.input_size   = cfg.input_size\n",
    "        self.output_size  = cfg.output_sizes[0]\n",
    "\n",
    "        self.border        = cfg.border\n",
    "        #self.lighting      = cfg.lighting\n",
    "        self.rand_crop     = cfg.rand_crop\n",
    "        print(self.rand_crop)\n",
    "        self.rand_color    = cfg.rand_color\n",
    "        self.rand_scales   = cfg.rand_scales\n",
    "        self.gaussian_bump = cfg.gaussian_bump\n",
    "        self.gaussian_iou  = cfg.gaussian_iou\n",
    "        self.gaussian_rad  = cfg.gaussian_radius\n",
    "    def read_from_disk(self,queue):\n",
    "        # allocating memory\n",
    "        max_tag_len = 128\n",
    "        image       = np.zeros((self.input_size[0], self.input_size[1],3), dtype=np.float32)\n",
    "        heatmaps_tl = np.zeros((self.output_size[0], self.output_size[1],self.categories), dtype=np.float32)\n",
    "        heatmaps_br = np.zeros((self.output_size[0], self.output_size[1],self.categories), dtype=np.float32)\n",
    "        offsets_tl    = np.zeros((max_tag_len, 2), dtype=np.float32)\n",
    "        offsets_br    = np.zeros((max_tag_len, 2), dtype=np.float32)\n",
    "        tags_tl     = np.zeros((max_tag_len), dtype=np.int64)\n",
    "        tags_br     = np.zeros((max_tag_len), dtype=np.int64)\n",
    "        tags_mask   = np.zeros((max_tag_len), dtype=np.float32)\n",
    "        boxes       = np.zeros((max_tag_len,4), dtype=np.int64)\n",
    "        ratio       = np.ones((max_tag_len,2), dtype=np.float32)\n",
    "        tag_lens    = 0\n",
    "\n",
    "        # reading image\n",
    "        image=self.coco.read_img(queue[0])\n",
    "\n",
    "        # reading detections\n",
    "        detections = self.coco.detections(queue[0])\n",
    "\n",
    "        # cropping an image randomly\n",
    "        if self.rand_crop:\n",
    "            image, detections = random_crop(image, detections, self.rand_scales, self.input_size, border=self.border)\n",
    "        else:\n",
    "            image, detections = full_image_crop(image, detections)\n",
    "\n",
    "        image, detections = resize_image(image, detections, self.input_size)\n",
    "        detections = clip_detections(image, detections)\n",
    "\n",
    "        width_ratio  = self.output_size[1] / self.input_size[1]\n",
    "        height_ratio = self.output_size[0] / self.input_size[0]\n",
    "\n",
    "        # flipping an image randomly\n",
    "        if np.random.uniform() > 0.5:\n",
    "            image[:] = image[:, ::-1, :]\n",
    "            width    = image.shape[1]\n",
    "            detections[:, [0, 2]] = width - detections[:, [2, 0]] - 1\n",
    "\n",
    "\n",
    "        image = image.astype(np.float32) / 255.\n",
    "\n",
    "\n",
    "        for ind, detection in enumerate(detections):\n",
    "            category = int(detection[-1]) - 1\n",
    "\n",
    "            xtl_ori, ytl_ori = detection[0], detection[1]\n",
    "            xbr_ori, ybr_ori = detection[2], detection[3]\n",
    "\n",
    "            fxtl = (xtl_ori * width_ratio)\n",
    "            fytl = (ytl_ori * height_ratio)\n",
    "            fxbr = (xbr_ori * width_ratio)\n",
    "            fybr = (ybr_ori * height_ratio)\n",
    "\n",
    "\n",
    "            xtl = int(fxtl)\n",
    "            ytl = int(fytl)\n",
    "            xbr = int(fxbr)\n",
    "            ybr = int(fybr)\n",
    "\n",
    "        # add heatmaps\n",
    "            if self.gaussian_bump:\n",
    "                width  = detection[2] - detection[0]\n",
    "                height = detection[3] - detection[1]\n",
    "\n",
    "                width  = math.ceil(width * width_ratio)\n",
    "                height = math.ceil(height * height_ratio)\n",
    "\n",
    "                if self.gaussian_rad == -1:\n",
    "                    radius = gaussian_radius((height, width), self.gaussian_iou)\n",
    "                    radius = max(0, int(radius))\n",
    "                else:\n",
    "                    radius = self.gaussian_rad\n",
    "\n",
    "                draw_gaussian(heatmaps_tl[:,:,category], [xtl, ytl], radius)\n",
    "                draw_gaussian(heatmaps_br[:,:,category], [xbr, ybr], radius)\n",
    "            else:\n",
    "                heatmaps_tl[ytl, xtl, category] = 1\n",
    "                heatmaps_br[ybr, xbr, category] = 1\n",
    "\n",
    "            tag_ind = tag_lens\n",
    "            offsets_tl[tag_ind, :] = [fxtl - xtl, fytl - ytl]\n",
    "            offsets_br[tag_ind, :] = [fxbr - xbr, fybr - ybr]\n",
    "            tags_tl[tag_ind] = ytl * self.output_size[1] + xtl\n",
    "            tags_br[tag_ind] = ybr * self.output_size[1] + xbr\n",
    "            boxes[tag_ind] = [xtl_ori,ytl_ori,xbr_ori,ybr_ori]\n",
    "            ratio[tag_ind] = [width_ratio,height_ratio]\n",
    "            tag_lens += 1\n",
    "        tags_mask[:tag_lens] = 1\n",
    "        return image, tags_tl, tags_br,heatmaps_tl, heatmaps_br, tags_mask, offsets_tl, offsets_br,boxes,ratio\n",
    "# get training data example by example using eager execution \n",
    "    def get_single_data(self,queue):\n",
    "        images, tags_tl, tags_br,heatmaps_tl, heatmaps_br, tags_mask, offsets_tl, offsets_br,boxes,ratio=tf.py_func(self.read_from_disk,[queue], [tf.float32,tf.int64,tf.int64,tf.float32,tf.float32,tf.float32,tf.float32,tf.float32,tf.int64,tf.float32])\n",
    "        return images, tags_tl, tags_br,heatmaps_tl, heatmaps_br, tags_mask, offsets_tl, offsets_br,boxes,ratio\n",
    "# slice all the training data   \n",
    "    def inupt_producer(self):\n",
    "        quene_train=tf.train.slice_input_producer([self.coco.get_all_img()],shuffle=True)\n",
    "        self.images, self.tags_tl, self.tags_br,self.heatmaps_tl, self.heatmaps_br, self.tags_mask, self.offsets_tl, self.offsets_br,self.boxes,self.ratio=self.get_single_data(quene_train)\n",
    "# batch training data\n",
    "    def get_batch_data(self,batch_size):\n",
    "        images, tags_tl, tags_br,heatmaps_tl, heatmaps_br, tags_mask, offsets_tl, offsets_br,boxes,ratio=tf.train.shuffle_batch([self.images,\n",
    "            self.tags_tl, self.tags_br,self.heatmaps_tl, self.heatmaps_br, self.tags_mask, self.offsets_tl, self.offsets_br,self.boxes,self.ratio],\n",
    "            batch_size=batch_size,shapes=[(self.input_size[0], self.input_size[1],3),(128),(128),\n",
    "            (self.output_size[0], self.output_size[1],self.categories),(self.output_size[0], self.output_size[1],self.categories),\n",
    "            (128),(128,2),(128,2),(128,4),(128,2)],capacity=100,min_after_dequeue=batch_size,num_threads=16)\n",
    "        return images, tags_tl, tags_br,heatmaps_tl, heatmaps_br, tags_mask, offsets_tl, offsets_br,boxes,ratio\n",
    "# execute data preparation\n",
    "if __name__=='__main__':\n",
    "    data=Image_data('trainval')\n",
    "    data.inupt_producer()\n",
    "    images, tags_tl, tags_br,heatmaps_tl, heatmaps_br, tags_mask, offsets_tl, offsets_br,boxes,ratio=data.get_batch_data(2)\n",
    "    sess=tf.InteractiveSession()\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads=tf.train.start_queue_runners(sess=sess,coord=coord)\n",
    "    for i in range(12):\n",
    "        images_, tags_tl_, tags_br_,heatmaps_tl_, heatmaps_br_, tags_mask_, offsets_tl_, offsets_br_,boxes_= sess.run([images, tags_tl, tags_br,heatmaps_tl, heatmaps_br, tags_mask, offsets_tl, offsets_br,boxes])\n",
    "        for j in range(2):\n",
    "            #print(images_.shape,tags_tl_.shape,heatmaps_tl_.shape,tags_mask_.shape,offsets_tl_.shape)\n",
    "            img=(images_[j]*255).astype(np.uint8)\n",
    "            heat_1=np.max(heatmaps_tl_[j],axis=-1)\n",
    "            heat_cat=np.zeros_like(heat_1)\n",
    "            heat_cat[np.where(heat_1==1)]=1\n",
    "            heat_arg=np.argmax(heat_cat,-1)\n",
    "            print(heat_arg)\n",
    "            heat_1=heat_1*255\n",
    "            heat_1=heat_1.astype(np.uint8)\n",
    "            heat_1=np.stack([heat_1,heat_1,heat_1],-1)\n",
    "\n",
    "            heat_2=np.max(heatmaps_br_[j],axis=-1)*255\n",
    "            heat_2=heat_2.astype(np.uint8)\n",
    "            heat_2=np.stack([heat_2,heat_2,heat_2],-1)\n",
    "\n",
    "            heat=heat_1+heat_2\n",
    "            heat=cv2.resize(heat,(511,511))\n",
    "            norm=cv2.addWeighted(img,0.5,heat,0.5,0)\n",
    "            box=boxes_[j]\n",
    "            for b in box:\n",
    "                cv2.rectangle(norm ,(b[0],b[1]),(b[2],b[3]),(225,225,0),1)\n",
    "            # shows image, but might crash jupyter session    \n",
    "            #cv2.imshow('img',norm)\n",
    "            cv2.waitKey(0)\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SVfngMxLKUZp"
   },
   "source": [
    "### Define the net \n",
    "\n",
    "Below, the entire model is put together. For overview, the entire architecture is depicted below. In particular, the feature extractor is defined as a so-called hourglass network. The feature maps are then fed into the prediction modules. \n",
    "\n",
    "![CornerNet architecture](examples/cornernet_architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HJ-DCM8cKKp6"
   },
   "outputs": [],
   "source": [
    "# model\n",
    "class Model():\n",
    "  # define concolutional layers of the predication module\n",
    "    def conv_bn_re(self,inputs,input_dim,out_dim,strides=(1,1),use_relu=True,use_bn=True,k=3,is_training=True,scope='conv_bn_re'):\n",
    "        with tf.variable_scope(scope):\n",
    "            x=tf.layers.conv2d(inputs,out_dim,k,strides=strides,padding='same')\n",
    "            if use_bn:\n",
    "                x=tf.contrib.layers.batch_norm(x,is_training=is_training)\n",
    "            if use_relu:\n",
    "                x=tf.nn.relu(x)\n",
    "            return x\n",
    "    # define residual connections        \n",
    "    def residual(self,inputs,input_dim,out_dim,k=3,strides=(1,1),is_training=True,scope='residual'):\n",
    "        with tf.variable_scope(scope):\n",
    "            #low layer 3*3>3*3\n",
    "            x=self.conv_bn_re(inputs,input_dim,out_dim,strides=strides,is_training=is_training,scope='up_1')\n",
    "            x=self.conv_bn_re(x,out_dim,out_dim,use_relu=False,is_training=is_training,scope='up_2')\n",
    "            #skip,up layer 1*1\n",
    "            skip=self.conv_bn_re(inputs,input_dim,out_dim,strides=strides,use_relu=False,k=1,is_training=is_training,scope='low')\n",
    "            #skip+x\n",
    "            res=tf.nn.relu(tf.add(skip,x))\n",
    "            return res\n",
    "    # define residual blocks for the hourglass network         \n",
    "    def res_block(self,inputs,input_dim,out_dim,n,k=3,is_training=True,scope='res_block'):\n",
    "        with tf.variable_scope(scope):\n",
    "            x=self.residual(inputs,input_dim,out_dim,k=k,is_training=is_training,scope='residual_0')\n",
    "            for i in range(1,n):\n",
    "                x=self.residual(x,out_dim,out_dim,k=k,is_training=is_training,scope='residual_%d'%i)\n",
    "            return x\n",
    "    # define hourglass network        \n",
    "    def hourglass(self,inputs,n_deep,n_res,n_dims,is_training=True,scope='hourglass_5'):\n",
    "        with tf.variable_scope(scope):\n",
    "            curr_res=n_res[0]\n",
    "            next_res=n_res[1]\n",
    "            curr_dim=n_dims[0]\n",
    "            next_dim=n_dims[1]\n",
    "\n",
    "            up_1=self.res_block(inputs,curr_dim,curr_dim,curr_res,is_training=is_training,scope='up_1')\n",
    "\n",
    "            half=tf.nn.max_pool(inputs,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "            low_1=self.res_block(half,curr_dim,next_dim,curr_res,is_training=is_training,scope='low_1')\n",
    "            if n_deep>1:\n",
    "                low_2=self.hourglass(low_1,n_deep-1,n_res[1:],n_dims[1:],is_training=is_training,scope='hourglass_%d'%(n_deep-1))\n",
    "            else:\n",
    "                low_2=self.res_block(low_1,next_dim,next_dim,next_res,is_training=is_training,scope='low_2')\n",
    "            low_3=self.res_block(low_2,next_dim,curr_dim,curr_res,is_training=is_training,scope='low_3')\n",
    "\n",
    "            up_2=tf.image.resize_nearest_neighbor(low_3,tf.shape(low_3)[1:3]*2,name='up_2')\n",
    "            merge=tf.add(up_1,up_2)\n",
    "            return merge\n",
    "    def start_conv(self,img,is_training=True,scope='start'):\n",
    "        with tf.variable_scope(scope):\n",
    "            x=tf.contrib.layers.conv2d(img,128,7,2)\n",
    "            x=tf.contrib.layers.batch_norm(x,is_training=is_training)\n",
    "            x=self.residual(x,128,256,strides=(2,2),scope='residual_start')\n",
    "            return x\n",
    "    # define corner pooling module in the prediction block        \n",
    "    def corner_pooling(self,inputs,input_dim,out_dim,k=3,is_training=True,scope='corner_pooling'):\n",
    "        with tf.variable_scope(scope):\n",
    "            with tf.variable_scope('top_left'):\n",
    "                top=self.conv_bn_re(inputs,input_dim,128,is_training=is_training,scope='top')\n",
    "                top_pool=TopPool(top)\n",
    "\n",
    "                left=self.conv_bn_re(inputs,input_dim,128,is_training=is_training,scope='left')\n",
    "                left_pool=LeftPool(left)\n",
    "\n",
    "                top_left=tf.add(top_pool,left_pool)\n",
    "                top_left=self.conv_bn_re(top_left,128,out_dim,use_relu=False,is_training=is_training,scope='top_left')\n",
    "\n",
    "                skip_tl=self.conv_bn_re(inputs,input_dim,out_dim,use_relu=False,k=1,is_training=is_training,scope='skip')\n",
    "\n",
    "                merge_tl=tf.nn.relu(tf.add(skip_tl,top_left))\n",
    "                merge_tl=self.conv_bn_re(merge_tl,out_dim,out_dim,is_training=is_training,scope='merge_tl')\n",
    "            with tf.variable_scope('bottom_right'):\n",
    "                bottom=self.conv_bn_re(inputs,input_dim,128,is_training=is_training,scope='bottom')\n",
    "                bottom_pool=BottomPool(bottom)\n",
    "\n",
    "                right=self.conv_bn_re(inputs,input_dim,128,is_training=is_training,scope='right')\n",
    "                right_pool=RightPool(right)\n",
    "\n",
    "                bottom_right=tf.add(bottom_pool,right_pool)\n",
    "                bottom_right=self.conv_bn_re(bottom_right,128,out_dim,use_relu=False,is_training=is_training,scope='bottom_right')\n",
    "\n",
    "                skip_br=self.conv_bn_re(inputs,input_dim,out_dim,use_relu=False,k=1,is_training=is_training,scope='skip')\n",
    "\n",
    "                merge_br=tf.nn.relu(tf.add(skip_br,bottom_right))\n",
    "                merge_br=self.conv_bn_re(merge_br,out_dim,out_dim,is_training=is_training,scope='merge_br')\n",
    "            return merge_tl,merge_br\n",
    "    # define forward passes\n",
    "    def heat(self,inputs,input_dim,out_dim,scope='heat'):\n",
    "        #out_dim=80\n",
    "        with tf.variable_scope(scope):\n",
    "            x=self.conv_bn_re(inputs,input_dim,input_dim,use_bn=False)\n",
    "            x=tf.layers.conv2d(x,out_dim,1)\n",
    "            return x\n",
    "    def tag(self,inputs,input_dim,out_dim,scope='tag'):\n",
    "        #out_dim=1\n",
    "        with tf.variable_scope(scope):\n",
    "            x=self.conv_bn_re(inputs,input_dim,input_dim,use_bn=False)\n",
    "            x=tf.layers.conv2d(x,out_dim,1)\n",
    "            return x\n",
    "    def offset(self,inputs,input_dim,out_dim,scope='offset'):\n",
    "        #out_dim=2\n",
    "        with tf.variable_scope(scope):\n",
    "            x=self.conv_bn_re(inputs,input_dim,input_dim,use_bn=False)\n",
    "            x=tf.layers.conv2d(x,out_dim,1)\n",
    "            return x\n",
    "    def hinge(self,inputs,input_dim,out_dim,is_training=True,scope='hinge'):\n",
    "        with tf.variable_scope(scope):\n",
    "            x=self.conv_bn_re(inputs,input_dim,out_dim,is_training=is_training)\n",
    "            return x\n",
    "    def inter(self,input_1,input_2,out_dim,is_training=True,scope='inter'):\n",
    "        with tf.variable_scope(scope):\n",
    "            x_1=self.conv_bn_re(input_1,tf.shape(input_1)[3],out_dim,use_relu=False,k=1,is_training=is_training,scope='branch_start')\n",
    "            x_2=self.conv_bn_re(input_2,tf.shape(input_2)[3],out_dim,use_relu=False,k=1,is_training=is_training,scope='branch_hourglass1')\n",
    "            x=tf.nn.relu(tf.add(x_1,x_2))\n",
    "            x=self.residual(x,out_dim,out_dim,is_training=is_training)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4r3q8wcXKpTO"
   },
   "outputs": [],
   "source": [
    "# put together all the modules of the network\n",
    "\n",
    "class NetWork():\n",
    "    def __init__(self,pull_weight=0.1, push_weight=0.1, offset_weight=1):\n",
    "      # configurations of the net\n",
    "        self.n_deep  = 5\n",
    "        self.n_dims  = [256, 256, 384, 384, 384, 512]\n",
    "        self.n_res   = [2, 2, 2, 2, 2, 4]\n",
    "        self.out_dim = 80\n",
    "        self.model=Model()\n",
    "        self.pull_weight = pull_weight\n",
    "        self.push_weight = push_weight\n",
    "        self.offset_weight = offset_weight\n",
    "        self.focal_loss  = focal_loss\n",
    "        self.tag_loss     = tag_loss\n",
    "        self.offset_loss   = offset_loss\n",
    "    def corner_net(self,img,gt_tag_tl=None,gt_tag_br=None,is_training=True,scope='CornerNet'):\n",
    "        with tf.variable_scope(scope):\n",
    "\n",
    "            outs=[]\n",
    "            test_outs=[]\n",
    "            start_layer=self.model.start_conv(img,is_training=is_training)#[b,128,128,256]\n",
    "\n",
    "            with tf.variable_scope('inter_supervise'):\n",
    "\n",
    "                hourglass_1=self.model.hourglass(start_layer,self.n_deep,self.n_res,self.n_dims,is_training=is_training)#[b,128,128,256]\n",
    "                hinge_is=self.model.hinge(hourglass_1,256,256,is_training=is_training)\n",
    "                top_left_is,bottom_right_is=self.model.corner_pooling(hinge_is,256,256,is_training=is_training)\n",
    "                #top_left\n",
    "                heat_tl_is=self.model.heat(top_left_is,256,self.out_dim,scope='heat_tl')\n",
    "                tag_tl_is=self.model.tag(top_left_is,256,1,scope='tag_tl')\n",
    "                if not gt_tag_tl is None:\n",
    "                    tag_tl_is=map_to_vector(tag_tl_is,gt_tag_tl)\n",
    "                offset_tl_is=self.model.offset(top_left_is,256,2,scope='offset_tl')\n",
    "                if not gt_tag_tl is None:\n",
    "                    offset_tl_is=map_to_vector(offset_tl_is,gt_tag_tl)\n",
    "                #bottom_right\n",
    "                heat_br_is=self.model.heat(bottom_right_is,256,self.out_dim,scope='heat_br')\n",
    "                tag_br_is=self.model.tag(bottom_right_is,256,1,scope='tag_br')\n",
    "                if not gt_tag_br is None:\n",
    "                    tag_br_is=map_to_vector(tag_br_is,gt_tag_br)\n",
    "                offset_br_is=self.model.offset(bottom_right_is,256,2,scope='offset_br')\n",
    "                if not gt_tag_br is None:\n",
    "                    offset_br_is=map_to_vector(offset_br_is,gt_tag_br)\n",
    "\n",
    "\n",
    "            with tf.variable_scope('master_branch'):\n",
    "                inter=self.model.inter(start_layer,hinge_is,256,is_training=is_training)\n",
    "                hourglass_2=self.model.hourglass(inter,self.n_deep,self.n_res,self.n_dims,is_training=is_training)#[b,128,128,256]\n",
    "                hinge=self.model.hinge(hourglass_2,256,256,is_training=is_training)\n",
    "                top_left,bottom_right=self.model.corner_pooling(hinge,256,256,is_training=is_training)\n",
    "                #top_left\n",
    "                heat_tl=self.model.heat(top_left,256,self.out_dim,scope='heat_tl')\n",
    "                tag_tl_test=self.model.tag(top_left,256,1,scope='tag_tl')\n",
    "                if not gt_tag_tl is None:\n",
    "                    tag_tl=map_to_vector(tag_tl_test,gt_tag_tl)\n",
    "                offset_tl_test=self.model.offset(top_left,256,2,scope='offset_tl')\n",
    "                if not gt_tag_tl is None:\n",
    "                    offset_tl=map_to_vector(offset_tl_test,gt_tag_tl)\n",
    "                #bottom_right\n",
    "                heat_br=self.model.heat(bottom_right,256,self.out_dim,scope='heat_br')\n",
    "                tag_br_test=self.model.tag(bottom_right,256,1,scope='tag_br')\n",
    "                if not gt_tag_br is None:\n",
    "                    tag_br=map_to_vector(tag_br_test,gt_tag_br)\n",
    "                offset_br_test=self.model.offset(bottom_right,256,2,scope='offset_br')\n",
    "                if not gt_tag_br is None:\n",
    "                    offset_br=map_to_vector(offset_br_test,gt_tag_br)\n",
    "\n",
    "            outs=[heat_tl_is,heat_br_is,tag_tl_is,tag_br_is,offset_tl_is,offset_br_is,heat_tl,heat_br,tag_tl,tag_br,offset_tl,offset_br]\n",
    "            test_outs=[heat_tl,heat_br,tag_tl_test,tag_br_test,offset_tl_test,offset_br_test]\n",
    "            return outs,test_outs\n",
    "    # call losses\n",
    "    def loss(self,outs,targets,scope='loss'):\n",
    "        with tf.variable_scope(scope):\n",
    "            stride = 6\n",
    "            heats_tl = outs[0::stride]\n",
    "            heats_br = outs[1::stride]\n",
    "            tags_tl  = outs[2::stride]\n",
    "            tags_br  = outs[3::stride]\n",
    "            offsets_tl = outs[4::stride]\n",
    "            offsets_br = outs[5::stride]\n",
    "\n",
    "            gt_heat_tl = targets[0]\n",
    "            gt_heat_br = targets[1]\n",
    "            gt_mask    = targets[2]\n",
    "            gt_offset_tl = targets[3]\n",
    "            gt_offset_br = targets[4]\n",
    "\n",
    "            # focal loss\n",
    "            focal_loss = 0\n",
    "\n",
    "            heats_tl = [tf.clip_by_value(tf.nn.sigmoid(tl),1e-4,1-1e-4) for tl in heats_tl]\n",
    "            heats_br = [tf.clip_by_value(tf.nn.sigmoid(br),1e-4,1-1e-4) for br in heats_br]\n",
    "\n",
    "            focal_loss += self.focal_loss(heats_tl, gt_heat_tl)\n",
    "            focal_loss += self.focal_loss(heats_br, gt_heat_br)\n",
    "\n",
    "            # tag loss\n",
    "            pull_loss = 0\n",
    "            push_loss = 0\n",
    "\n",
    "            for tag_tl, tag_br in zip(tags_tl, tags_br):\n",
    "                pull, push = self.tag_loss(tag_tl, tag_br, gt_mask)\n",
    "                pull_loss += pull\n",
    "                push_loss += push\n",
    "\n",
    "            pull_loss = self.pull_weight * pull_loss\n",
    "            push_loss = self.push_weight * push_loss\n",
    "\n",
    "            offset_loss = 0\n",
    "            for offset_tl, offset_br in zip(offsets_tl, offsets_br):\n",
    "                offset_loss += self.offset_loss(offset_tl, gt_offset_tl, gt_mask)\n",
    "                offset_loss += self.offset_loss(offset_br, gt_offset_br, gt_mask)\n",
    "            offset_loss = self.offset_weight * offset_loss\n",
    "\n",
    "            loss = (focal_loss + pull_loss + push_loss + offset_loss) / len(heats_tl)\n",
    "            return loss,focal_loss,pull_loss,push_loss,offset_loss\n",
    "    # retrieve detections          \n",
    "    def decode(self,heat_tl,heat_br,tag_tl,tag_br,offset_tl,offset_br,k=100,ae_threshold=0.5,num_dets=1000):\n",
    "        batch=tf.shape(heat_br)[0]\n",
    "        heat_tl=tf.nn.sigmoid(heat_tl)\n",
    "        heat_br=tf.nn.sigmoid(heat_br)\n",
    "        #nms\n",
    "        heat_tl=nms(heat_tl)\n",
    "        heat_br=nms(heat_br)\n",
    "        value_tl,position_tl,class_tl,y_tl,x_tl=top_k(heat_tl,k)\n",
    "        value_br,position_br,class_br,y_br,x_br=top_k(heat_br,k)\n",
    "\n",
    "        #expand to square\n",
    "        x_tl=tf.cast(expand_copy(x_tl,k,False),tf.float32)\n",
    "        y_tl=tf.cast(expand_copy(y_tl,k,False),tf.float32)\n",
    "        x_br=tf.cast(expand_copy(x_br,k,True),tf.float32)\n",
    "        y_br=tf.cast(expand_copy(y_br,k,True),tf.float32)\n",
    "\n",
    "\n",
    "        offset_tl=map_to_vector(offset_tl,position_tl)\n",
    "        offset_br=map_to_vector(offset_br,position_br)\n",
    "        offset_tl=tf.reshape(offset_tl,(offset_tl.get_shape().as_list()[0],k,1,2))\n",
    "        offset_br=tf.reshape(offset_br,(offset_br.get_shape().as_list()[0],1,k,2))\n",
    "\n",
    "\n",
    "        x_tl=x_tl+offset_tl[:,:,:,0]\n",
    "        y_tl=y_tl+offset_tl[:,:,:,1]\n",
    "        x_br=x_br+offset_br[:,:,:,0]\n",
    "        y_br=y_br+offset_br[:,:,:,1]\n",
    "\n",
    "        offset_tl=tf.reshape(offset_tl,(batch,k,1,2))\n",
    "        offset_br=tf.reshape(offset_br,(batch,1,k,2))\n",
    "\n",
    "        #all k boxes\n",
    "        bboxes=tf.stack((x_tl,y_tl,x_br,y_br),axis=-1)\n",
    "\n",
    "        tag_tl=map_to_vector(tag_tl,position_tl)\n",
    "        tag_tl=tf.reshape(tag_tl,(batch,k,1))\n",
    "        tag_br=map_to_vector(tag_br,position_br)\n",
    "        tag_br=tf.reshape(tag_br,(batch,1,k))\n",
    "        dists=tf.abs(tag_tl-tag_br)\n",
    "\n",
    "        value_tl=expand_copy(value_tl,k,False)\n",
    "        value_br=expand_copy(value_br,k,True)\n",
    "        scores=(value_tl+value_br)/2\n",
    "        invalid=-tf.ones_like(scores)\n",
    "\n",
    "        #======debug=====\n",
    "        debug_scores=tf.reshape(scores,(batch,-1))\n",
    "        debug_scores,debug_indexs=tf.nn.top_k(debug_scores,10)\n",
    "        debug_bboxes=tf.reshape(bboxes,(batch,-1,4))\n",
    "        debug_bboxes=map_to_vector(debug_bboxes,debug_indexs,transpose=False)\n",
    "        #======debug=====\n",
    "\n",
    "        class_tl=tf.cast(expand_copy(class_tl,k,False),tf.float32)#[batch,k,k]\n",
    "        class_br=tf.cast(expand_copy(class_br,k,True),tf.float32)\n",
    "\n",
    "        mask_scores=tf.where(tf.cast(tf.equal(class_tl,class_br),tf.int32)>0,scores,invalid)\n",
    "        mask_scores=tf.where(tf.less(dists,ae_threshold),mask_scores,invalid)\n",
    "        mask_scores=tf.where(tf.less(x_tl,x_br),mask_scores,invalid)\n",
    "        mask_scores=tf.where(tf.less(y_tl,y_br),mask_scores,invalid)\n",
    "\n",
    "        mask_scores=tf.reshape(mask_scores,(batch,-1))\n",
    "        scores,indexs=tf.nn.top_k(mask_scores,num_dets)\n",
    "        scores=tf.expand_dims(scores,-1)\n",
    "\n",
    "        bboxes=tf.reshape(bboxes,(batch,-1,4))\n",
    "        bboxes=map_to_vector(bboxes,indexs,transpose=False)\n",
    "\n",
    "        class_=tf.reshape(class_br,(batch,-1,1))\n",
    "        class_=map_to_vector(class_,indexs,transpose=False)\n",
    "\n",
    "        value_tl=tf.reshape(value_tl,(batch,-1,1))\n",
    "        value_tl=map_to_vector(value_tl,indexs,transpose=False)\n",
    "\n",
    "        value_br=tf.reshape(value_br,(batch,-1,1))\n",
    "        value_br=map_to_vector(value_br,indexs,transpose=False)\n",
    "\n",
    "        detection=tf.concat([bboxes,scores,value_tl,value_br,class_],-1)\n",
    "        return detection,debug_bboxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K5LQu3I6K1b3"
   },
   "source": [
    "Now that the model is defined, it can be trained and tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mlPKWzZfMapB"
   },
   "outputs": [],
   "source": [
    "# testing\n",
    "\n",
    "class Test():\n",
    "    def __init__(self):\n",
    "        self.coco=MSCOCO('minival')\n",
    "        self.net=NetWork()\n",
    "        self.top_k=cfg.top_k\n",
    "        self.ae_threshold=cfg.ae_threshold\n",
    "        self.test_scales=cfg.test_scales\n",
    "        self.weight_exp=cfg.weight_exp\n",
    "        self.merge_bbox=cfg.merge_bbox\n",
    "        self.categories=cfg.categories\n",
    "        self.nms_threshold=cfg.nms_threshold\n",
    "        self.max_per_image=cfg.max_per_image\n",
    "        self.result_dir=cfg.result_dir\n",
    "    def test(self,sess):\n",
    "        debug_dir = os.path.join(result_dir, \"debug\")\n",
    "        if not os.path.exists(debug_dir):\n",
    "            os.makedirs(debug_dir)\n",
    "        img_names=self.coco.get_all_img()\n",
    "        num=len(img_names)\n",
    "        for img_name in tqdm(img_names):\n",
    "            img=self.coco.read_img(img_name)\n",
    "            height, width = img.shape[0:2]\n",
    "            detections=[]\n",
    "            for scale in test_scales:\n",
    "                new_height = int(height * scale)\n",
    "                new_width  = int(width * scale)\n",
    "                new_center = np.array([new_height // 2, new_width // 2])\n",
    "\n",
    "                inp_height = new_height | 127\n",
    "                inp_width  = new_width  | 127\n",
    "\n",
    "                images  = np.zeros((1, inp_height, inp_width, 3), dtype=np.float32)\n",
    "                ratios  = np.zeros((1, 2), dtype=np.float32)\n",
    "                borders = np.zeros((1, 4), dtype=np.float32)\n",
    "                sizes   = np.zeros((1, 2), dtype=np.float32)\n",
    "\n",
    "                out_height, out_width = (inp_height + 1) // 4, (inp_width + 1) // 4\n",
    "                height_ratio = out_height / inp_height\n",
    "                width_ratio  = out_width  / inp_width\n",
    "\n",
    "                resized_image = cv2.resize(image, (new_width, new_height))\n",
    "                resized_image, border, offset = crop_image(resized_image, new_center, [inp_height, inp_width])\n",
    "\n",
    "                resized_image = resized_image / 255.\n",
    "\n",
    "                images[0]  = resized_image            \n",
    "                borders[0] = border\n",
    "                sizes[0]   = [int(height * scale), int(width * scale)]\n",
    "                ratios[0]  = [height_ratio, width_ratio]\n",
    "\n",
    "                images = np.concatenate((images, images[:, :, ::-1, :]), axis=0)\n",
    "                images = tf.convert_to_tensor(images)\n",
    "                is_training=tf.convert_to_tensor(False)\n",
    "                outs=self.net.corner_net(images,is_training=is_training)\n",
    "                dets_tensor=self.net.decode(*outs[-6:])\n",
    "                dets=sess.run(dets_tensor)\n",
    "\n",
    "                dets   = dets.reshape(2, -1, 8)\n",
    "                dets[1, :, [0, 2]] = out_width - dets[1, :, [2, 0]]\n",
    "                dets   = dets.reshape(1, -1, 8)\n",
    "\n",
    "                dets=rescale_dets(dets, ratios, borders, sizes)\n",
    "                dets[:, :, 0:4] /= scale\n",
    "                detections.append(dets)\n",
    "\n",
    "            detections = np.concatenate(detections, axis=1)\n",
    "            classes    = detections[..., -1]\n",
    "            classes    = classes[0]\n",
    "            detections = detections[0]\n",
    "\n",
    "            # reject detections with negative scores\n",
    "            keep_inds  = (detections[:, 4] > -1)\n",
    "            detections = detections[keep_inds]\n",
    "            classes    = classes[keep_inds]\n",
    "\n",
    "            top_bboxes[image_id] = {}\n",
    "            for j in range(categories):\n",
    "                keep_inds = (classes == j)\n",
    "                top_bboxes[image_id][j + 1] = detections[keep_inds][:, 0:7].astype(np.float32)\n",
    "                if merge_bbox:\n",
    "                    top_bboxes[image_id][j + 1]=soft_nms_merge(top_bboxes[image_id][j + 1], Nt=nms_threshold, method=2, weight_exp=weight_exp)\n",
    "                else:\n",
    "                    top_bboxes[image_id][j + 1]=soft_nms(top_bboxes[image_id][j + 1], Nt=nms_threshold, method=nms_algorithm)\n",
    "                top_bboxes[image_id][j + 1] = top_bboxes[image_id][j + 1][:, 0:5]\n",
    "\n",
    "            scores = np.hstack([\n",
    "                top_bboxes[image_id][j][:, -1]\n",
    "                for j in range(1, categories + 1)\n",
    "            ])\n",
    "            if len(scores) > max_per_image:\n",
    "                kth    = len(scores) - max_per_image\n",
    "                thresh = np.partition(scores, kth)[kth]\n",
    "                for j in range(1, categories + 1):\n",
    "                    keep_inds = (top_bboxes[image_id][j][:, -1] >= thresh)\n",
    "                    top_bboxes[image_id][j] = top_bboxes[image_id][j][keep_inds]\n",
    "\n",
    "            if debug:\n",
    "                image=self.coco.read_img(img_name)\n",
    "\n",
    "                bboxes = {}\n",
    "                for j in range(1, categories + 1):\n",
    "                    keep_inds = (top_bboxes[image_id][j][:, -1] > 0.5)\n",
    "                    cat_name  = self.coco.class_name(j)\n",
    "                    cat_size  = cv2.getTextSize(cat_name, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]\n",
    "                    color     = np.random.random((3, )) * 0.6 + 0.4\n",
    "                    color     = color * 255\n",
    "                    color     = color.astype(np.int32).tolist()\n",
    "                    for bbox in top_bboxes[image_id][j][keep_inds]:\n",
    "                        bbox  = bbox[0:4].astype(np.int32)\n",
    "                        if bbox[1] - cat_size[1] - 2 < 0:\n",
    "                            cv2.rectangle(image,\n",
    "                                (bbox[0], bbox[1] + 2),\n",
    "                                (bbox[0] + cat_size[0], bbox[1] + cat_size[1] + 2),\n",
    "                                color, -1\n",
    "                            )\n",
    "                            cv2.putText(image, cat_name,\n",
    "                                (bbox[0], bbox[1] + cat_size[1] + 2),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), thickness=1\n",
    "                            )\n",
    "                        else:\n",
    "                            cv2.rectangle(image,\n",
    "                                (bbox[0], bbox[1] - cat_size[1] - 2),\n",
    "                                (bbox[0] + cat_size[0], bbox[1] - 2),\n",
    "                                color, -1\n",
    "                            )\n",
    "                            cv2.putText(image, cat_name,\n",
    "                                (bbox[0], bbox[1] - 2),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), thickness=1\n",
    "                            )\n",
    "                        cv2.rectangle(image,\n",
    "                            (bbox[0], bbox[1]),\n",
    "                            (bbox[2], bbox[3]),\n",
    "                            color, 2\n",
    "                        )\n",
    "                debug_file = os.path.join(debug_dir, {}.format(img_name))\n",
    "\n",
    "        # result_json = os.path.join(result_dir, \"results.json\")\n",
    "        # detections  = db.convert_to_coco(top_bboxes)\n",
    "        # with open(result_json, \"w\") as f:\n",
    "        #     json.dump(detections, f)\n",
    "\n",
    "        # cls_ids   = list(range(1, categories + 1))\n",
    "        # image_ids = [db.image_ids(ind) for ind in db_inds]\n",
    "        # db.evaluate(result_json, cls_ids, image_ids)\n",
    "        return 0\n",
    "# define debug funtions to use during training        \n",
    "class Debug():\n",
    "    def __init__(self):\n",
    "        self.top_k=cfg.top_k\n",
    "        self.ae_threshold=cfg.ae_threshold\n",
    "        self.test_scales=cfg.test_scales\n",
    "        self.weight_exp=cfg.weight_exp\n",
    "        self.merge_bbox=cfg.merge_bbox\n",
    "        self.categories=cfg.categories\n",
    "        self.nms_threshold=cfg.nms_threshold\n",
    "        self.max_per_image=cfg.max_per_image\n",
    "        self.debug_dir=cfg.debug_dir\n",
    "    def test_debug(self,image,detections,debug_boxes,boxes,ratio,coco,step):\n",
    "        detections   = detections.reshape(-1, 8)\n",
    "        detections[:, 0:4:2] /= ratio[0]\n",
    "        detections[:, 1:4:2] /= ratio[1]\n",
    "        debug_boxes=debug_boxes.reshape(-1,4)\n",
    "        debug_boxes[:,0:4:2] /= ratio[0]\n",
    "        debug_boxes[:,1:4:2] /= ratio[1]\n",
    "\n",
    "        classes    = detections[..., -1].astype(np.int64)\n",
    "\n",
    "        # reject detections with negative scores\n",
    "        keep_inds  = (detections[:, 4] > -1)\n",
    "        detections = detections[keep_inds]\n",
    "        classes    = classes[keep_inds]\n",
    "\n",
    "        top_bboxes = {}\n",
    "        for j in range(self.categories):\n",
    "            keep_inds = (classes == j)\n",
    "            top_bboxes[j + 1] = detections[keep_inds][:, 0:7].astype(np.float32)\n",
    "            if self.merge_bbox:\n",
    "                top_bboxes[j + 1]=soft_nms_merge(top_bboxes[j + 1], Nt=0.5, method=2, weight_exp=8)\n",
    "            else:\n",
    "                top_bboxes[j + 1]=soft_nms(top_bboxes[j + 1], Nt=0.5, method=2)\n",
    "            top_bboxes[j + 1] = top_bboxes[j + 1][:, 0:5]\n",
    "\n",
    "        scores = np.hstack([\n",
    "            top_bboxes[j][:, -1]\n",
    "            for j in range(1, self.categories + 1)\n",
    "        ])\n",
    "        if len(scores) > self.max_per_image:\n",
    "            kth    = len(scores) - self.max_per_image\n",
    "            thresh = np.partition(scores, kth)[kth]\n",
    "            for j in range(1, self.categories + 1):\n",
    "                keep_inds = (top_bboxes[j][:, -1] >= thresh)\n",
    "                top_bboxes[j] = top_bboxes[j][keep_inds]\n",
    "\n",
    "\n",
    "        image=(image*255).astype(np.uint8)\n",
    "\n",
    "        bboxes = {}\n",
    "        for j in range(1, self.categories + 1):\n",
    "            #if step>10000:\n",
    "            keep_inds = (top_bboxes[j][:, -1] > 0.5)\n",
    "            top_bboxes[j]=top_bboxes[j][keep_inds]\n",
    "            cat_name  = coco.class_name(j)\n",
    "            cat_size  = cv2.getTextSize(cat_name, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]\n",
    "            color     = np.random.random((3, )) * 0.6 + 0.4\n",
    "            color     = color * 255\n",
    "            color     = color.astype(np.int32).tolist()\n",
    "            for bbox in top_bboxes[j]:\n",
    "                bbox  = bbox[0:4].astype(np.int32)\n",
    "                if bbox[1] - cat_size[1] - 2 < 0:\n",
    "                    cv2.rectangle(image,\n",
    "                        (bbox[0], bbox[1] + 2),\n",
    "                        (bbox[0] + cat_size[0], bbox[1] + cat_size[1] + 2),\n",
    "                        color, -1\n",
    "                    )\n",
    "                    cv2.putText(image, cat_name,\n",
    "                        (bbox[0], bbox[1] + cat_size[1] + 2),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), thickness=1\n",
    "                    )\n",
    "                else:\n",
    "                    cv2.rectangle(image,\n",
    "                        (bbox[0], bbox[1] - cat_size[1] - 2),\n",
    "                        (bbox[0] + cat_size[0], bbox[1] - 2),\n",
    "                        color, -1\n",
    "                    )\n",
    "                    cv2.putText(image, cat_name,\n",
    "                        (bbox[0], bbox[1] - 2),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), thickness=1\n",
    "                    )\n",
    "                cv2.rectangle(image,\n",
    "                    (bbox[0], bbox[1]),\n",
    "                    (bbox[2], bbox[3]),\n",
    "                    color, 2\n",
    "                )\n",
    "            for b in boxes:\n",
    "                cv2.rectangle(image ,(b[0],b[1]),(b[2],b[3]),(0,0,255),1)\n",
    "        for i in range(len(debug_boxes)):\n",
    "            color     = np.random.random((3, )) * 0.6 + 0.4\n",
    "            color     = color * 255\n",
    "            color     = color.astype(np.int32).tolist()\n",
    "            cv2.circle(image,(debug_boxes[i][0],debug_boxes[i][1]),2,color,2)\n",
    "            cv2.circle(image,(debug_boxes[i][2],debug_boxes[i][3]),2,color,2)\n",
    "        cv2.imwrite(os.path.join(self.debug_dir,str(step)+'.jpg'),image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nLh2HdG_MM7u"
   },
   "outputs": [],
   "source": [
    "# training\n",
    "\n",
    "class Train():\n",
    "    def __init__(self):\n",
    "        os.environ['CUDA_VISIBLE_DEVICES']='0,1'\n",
    "        self.net=NetWork()\n",
    "        self.data_train=Image_data('trainval')\n",
    "        self.data_train.inupt_producer()\n",
    "        self.gpus=[0,1]\n",
    "        self.batch_i=cfg.batch_size\n",
    "        self.batch_size=self.batch_i*len(self.gpus)\n",
    "        self.save_pre_every=int(self.data_train.num_image/self.batch_size)+1\n",
    "        # for purposes of making this example, manually set to a relatively low number \n",
    "        self.num_steps= 100 #int(self.save_pre_every*cfg.epoch_num+1)\n",
    "        self.lr=cfg.learning_rate\n",
    "        self.snapshot_dir=cfg.snapshot_dir\n",
    "        self.snapshot_file=cfg.snapshot_file\n",
    "        self.decay_rate=cfg.decay_rate\n",
    "        self.decay_step=cfg.decay_step\n",
    "\n",
    "# parallelized training  ----- crashes Google Colab -----\n",
    "    def train_mult(self):\n",
    "        coord = tf.train.Coordinator()\n",
    "        images, tags_tl, tags_br,heatmaps_tl, heatmaps_br, tags_mask, offsets_tl, offsets_br,boxes,ratio=self.data_train.get_batch_data(self.batch_size)\n",
    "        tower_grads = []\n",
    "        steps=tf.Variable(0,name='global_step',trainable=False)\n",
    "        lr=tf.train.exponential_decay(self.lr,steps,self.decay_step,self.decay_rate,staircase= True, name= 'learning_rate')\n",
    "        optim=tf.train.AdamOptimizer(learning_rate=lr)\n",
    "        reuse1 = False\n",
    "        for i in range(len(self.gpus)):\n",
    "            with tf.device('/gpu:%d'%i):\n",
    "                with tf.name_scope('Tower_%d' % (i)) as scope:\n",
    "                    if i == 0:\n",
    "                        reuse1 = False\n",
    "                    else:\n",
    "                        reuse1 = True\n",
    "\n",
    "                    next_imgs=images[i*self.batch_i:(i+1)*self.batch_i]\n",
    "                    next_tags_tl=tags_tl[i*self.batch_i:(i+1)*self.batch_i]\n",
    "                    next_tags_br=tags_br[i*self.batch_i:(i+1)*self.batch_i]\n",
    "                    next_heatmaps_tl=heatmaps_tl[i*self.batch_i:(i+1)*self.batch_i]\n",
    "                    next_heatmaps_br=heatmaps_br[i*self.batch_i:(i+1)*self.batch_i]\n",
    "                    next_tags_mask=tags_mask[i*self.batch_i:(i+1)*self.batch_i]\n",
    "                    next_offsets_tl=offsets_tl[i*self.batch_i:(i+1)*self.batch_i]\n",
    "                    next_offsets_br=offsets_br[i*self.batch_i:(i+1)*self.batch_i]\n",
    "                    with tf.variable_scope('', reuse=reuse1):\n",
    "                        outs,test_outs=self.net.corner_net(next_imgs,next_tags_tl,next_tags_br,is_training=True)\n",
    "                    dets_tensor,debug_boxes=self.net.decode(*test_outs)\n",
    "\n",
    "                    loss,focal_loss,pull_loss,push_loss,offset_loss=self.net.loss(outs,[next_heatmaps_tl,next_heatmaps_br,next_tags_mask,next_offsets_tl,next_offsets_br])\n",
    "                    trainable_variable = tf.trainable_variables()\n",
    "                    grads = optim.compute_gradients(loss, var_list=trainable_variable)\n",
    "\n",
    "\n",
    "                    tower_grads.append(grads)\n",
    "\n",
    "        grads_ave = self.average_gradients(tower_grads)\n",
    "        update=tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update):\n",
    "            train_op = optim.apply_gradients(grads_ave,steps)\n",
    "\n",
    "        saver = tf.train.Saver(max_to_keep=100)\n",
    "        #loader = tf.train.Saver()\n",
    "        config = tf.ConfigProto(allow_soft_placement=True,log_device_placement=False)\n",
    "        config.gpu_options.allow_growth = True\n",
    "        sess = tf.Session(config=config)\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "        threads = tf.train.start_queue_runners(coord=coord, sess=sess)\n",
    "        print(self.num_steps)\n",
    "        debug=Debug()\n",
    "        epoch=0\n",
    "        if self.load(saver, sess, self.snapshot_dir):\n",
    "            print(\" [*] Load SUCCESS\")\n",
    "        else:\n",
    "            print(\" [!] Load failed...\")\n",
    "        for step in range(self.num_steps):\n",
    "            start=time.time()\n",
    "            #sess.run(update)\n",
    "            _,loss_,focal_loss_,pull_loss_,push_loss_,offset_loss_,lr_=sess.run([train_op,loss,focal_loss,pull_loss,push_loss,offset_loss,lr])\n",
    "            duration=time.time()-start\n",
    "\n",
    "            print('step %d, loss %g, focal_loss %g, pull_loss %g, push_loss %g, offset_loss %g, time %g, lr %g'\n",
    "                %(step,loss_,focal_loss_,pull_loss_,push_loss_,offset_loss_,duration,lr_))\n",
    "\n",
    "            if step%100==0:\n",
    "                dets_,images_,debug_boxes_,boxes_,ratio_=sess.run([dets_tensor,images,debug_boxes,boxes,ratio])\n",
    "                debug.test_debug(images_[0],dets_[0],debug_boxes_[0],boxes_[0],ratio_[0],self.data_train.coco,step)\n",
    "            if step % self.save_pre_every == 0 and step>0:\n",
    "                saver.save(sess, self.snapshot_file, epoch)\n",
    "                epoch+=1\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "    def average_gradients(self,tower_grads):\n",
    "        average_grads = []\n",
    "        for grad_and_vars in zip(*tower_grads):\n",
    "            # Note that each grad_and_vars looks like the following:\n",
    "            #   ((grad0_gpu0, var0_gpu0), ... , (grad0_gpuN, var0_gpuN))\n",
    "            grads = []\n",
    "            for g, _ in grad_and_vars:\n",
    "                # Add 0 dimension to the gradients to represent the tower.\n",
    "\n",
    "                expanded_g = tf.expand_dims(g, 0)\n",
    "                # Append on a 'tower' dimension which we will average over below.\n",
    "                grads.append(expanded_g)\n",
    "            # Average over the 'tower' dimension.\n",
    "            grad = tf.concat(axis=0, values=grads)\n",
    "            grad = tf.reduce_mean(grad, 0)\n",
    "            # Keep in mind that the Variables are redundant because they are shared\n",
    "            # across towers. So .. we will just return the first tower's pointer to\n",
    "            # the Variable.\n",
    "            v = grad_and_vars[0][1]\n",
    "            grad_and_var = (grad, v)\n",
    "            average_grads.append(grad_and_var)\n",
    "        return average_grads\n",
    "\n",
    "    def load(self,saver, sess, ckpt_path):\n",
    "        '''Load trained weights.\n",
    "        Args:\n",
    "          saver: TensorFlow saver object.\n",
    "          sess: TensorFlow session.\n",
    "          ckpt_path: path to checkpoint file with parameters.\n",
    "        '''\n",
    "        ckpt = tf.train.get_checkpoint_state(ckpt_path)\n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
    "            saver.restore(sess, os.path.join(ckpt_path, ckpt_name))\n",
    "            print(\"Restored model parameters from {}\".format(ckpt_name))\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "            \n",
    "# training on one device\n",
    "    def train_single(self):\n",
    "        images, tags_tl, tags_br,heatmaps_tl, heatmaps_br, tags_mask, offsets_tl, offsets_br,boxes,ratio=self.data_train.get_batch_data(self.batch_i)\n",
    "\n",
    "        # track sreps and losses for plotting\n",
    "        step_list = []\n",
    "        total_loss_list = []\n",
    "        focal_loss_list = []\n",
    "        offset_loss_list = []\n",
    "\n",
    "        outs,test_outs=self.net.corner_net(images,tags_tl,tags_br,is_training=True)\n",
    "        dets_tensor,debug_boxes=self.net.decode(*test_outs)\n",
    "        loss,focal_loss,pull_loss,push_loss,offset_loss=self.net.loss(outs,[heatmaps_tl,heatmaps_br,tags_mask,offsets_tl,offsets_br])\n",
    "\n",
    "        steps=tf.Variable(0,name='global_step',trainable=False)\n",
    "        lr=tf.train.exponential_decay(self.lr,steps,self.decay_step,self.decay_rate,staircase= True, name= 'learning_rate')\n",
    "\n",
    "        update=tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        train_op=tf.train.AdamOptimizer(learning_rate=lr).minimize(loss,steps)\n",
    "        config=tf.ConfigProto()\n",
    "        config.gpu_options.allow_growth=True\n",
    "        sess=tf.InteractiveSession(config=config)\n",
    "        init=tf.global_variables_initializer()\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads=tf.train.start_queue_runners(sess=sess,coord=coord)\n",
    "        saver=tf.train.Saver(max_to_keep=100)\n",
    "        sess.run(init)\n",
    "        print(self.num_steps)\n",
    "        debug=Debug()\n",
    "        epoch=5\n",
    "        if self.load(saver, sess, self.snapshot_dir):\n",
    "            print(\" [*] Load SUCCESS\")\n",
    "        else:\n",
    "            print(\" [!] Load failed...\")\n",
    "        for step in range(self.num_steps):\n",
    "\n",
    "            start=time.time()\n",
    "            sess.run(update)\n",
    "            _,loss_,focal_loss_,pull_loss_,push_loss_,offset_loss_,lr_=sess.run([train_op,loss,focal_loss,pull_loss,push_loss,offset_loss,lr])\n",
    "\n",
    "            duration=time.time()-start\n",
    "\n",
    "            print('step %d, loss %g, focal_loss %g, pull_loss %g, push_loss %g, offset_loss %g, time %g, lr %g'\n",
    "                %(step,loss_,focal_loss_,pull_loss_,push_loss_,offset_loss_,duration,lr_))\n",
    "            \n",
    "            step_list.append(step)\n",
    "            total_loss_list.append(loss_)\n",
    "            # focal_loss_list = focal_loss_list.append(focal_loss_)\n",
    "            # offset_loss_list = offset_loss_list.append(offset_loss_)\n",
    "\n",
    "            if step%10==0:\n",
    "                dets_,images_,debug_boxes_,boxes_,ratio_=sess.run([dets_tensor,images,debug_boxes,boxes,ratio])\n",
    "                debug.test_debug(images_[0],dets_[0],debug_boxes_[0],boxes_[0],ratio_[0],self.data_train.coco,step)\n",
    "            if step % self.save_pre_every == 0 and step>0:\n",
    "                saver.save(sess, self.snapshot_file, epoch)\n",
    "                epoch+=1\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "        return step_list, total_loss_list #, focal_loss_list, offset_loss_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DXVXdrQDArif"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zK6ToJCeuM5L"
   },
   "outputs": [],
   "source": [
    "# if you want to re-run the following cell a second time, you need to re-initialize the computation graph because it already exists with:\n",
    "tf.reset_default_graph() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Okl85BJDG6S"
   },
   "source": [
    "The training can only be completed on the available RAM for a small number of training steps (set to 100). But during training, example images with detected objects are generated which can be viewed at the beginning of the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O3rBpw1Ep_0V",
    "outputId": "0d9e61fb-ded2-4b55-cc6d-97d5a1bb17bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/cocoapi/annotations/instances_val2017.json\n",
      "loading from cache file: ./cache/coco_val2017.pkl\n",
      "loading annotations into memory...\n",
      "Done (t=0.60s)\n",
      "creating index...\n",
      "index created!\n",
      "True\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From <ipython-input-25-15dc5fb1a521>:6: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "WARNING:tensorflow:From <ipython-input-26-9ed02cf8b4e3>:174: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "[5, 128, 128, 80]\n",
      "[5, 128, 128, 80]\n",
      "[5, 128, 1]\n",
      "[5, 128, 1]\n",
      "b'000000412240.jpg'\n",
      "b'000000480212.jpg'\n",
      "b'000000157756.jpg'\n",
      "b'000000224222.jpg'\n",
      "b'000000568147.jpg'\n",
      "b'000000068628.jpg'\n",
      "b'000000245102.jpg'\n",
      "b'000000289415.jpg'\n",
      "b'000000575187.jpg'\n",
      "b'000000084752.jpg'\n",
      "b'000000074860.jpg'\n",
      "b'000000462756.jpg'\n",
      "b'000000267946.jpg'\n",
      "b'000000131556.jpg'\n",
      "b'000000054593.jpg'\n",
      "b'000000477623.jpg'\n",
      "b'000000017029.jpg'\n",
      "b'000000557916.jpg'\n",
      "b'000000015338.jpg'\n",
      "b'000000018380.jpg'\n",
      "b'000000373382.jpg'\n",
      "b'000000106048.jpg'\n",
      "b'000000076625.jpg'\n",
      "b'000000092839.jpg'\n",
      "b'000000183675.jpg'\n",
      "b'000000052007.jpg'\n",
      "b'000000324818.jpg'b'000000183648.jpg'\n",
      "\n",
      "b'000000462904.jpg'\n",
      "b'000000062692.jpg'\n",
      "b'000000414034.jpg'\n",
      "b'000000185950.jpg'\n",
      "b'000000421455.jpg'\n",
      "b'000000573094.jpg'\n",
      "b'000000557672.jpg'\n",
      "b'000000266768.jpg'\n",
      "b'000000301867.jpg'\n",
      "b'000000191761.jpg'\n",
      "b'000000425226.jpg'\n",
      "b'000000066561.jpg'\n",
      "b'000000092177.jpg'\n",
      "b'000000060835.jpg'\n",
      "b'000000078266.jpg'\n",
      "b'000000521819.jpg'\n",
      "b'000000367195.jpg'\n",
      "b'000000344029.jpg'\n",
      "b'000000498807.jpg'\n",
      "b'000000399296.jpg'\n",
      "b'000000210520.jpg'\n",
      "b'000000223188.jpg'\n",
      "b'000000161820.jpg'\n",
      "b'000000052007.jpg'b'000000314709.jpg'\n",
      "\n",
      "b'000000283037.jpg'\n",
      "b'000000319534.jpg'\n",
      "b'000000438774.jpg'\n",
      "b'000000514914.jpg'\n",
      "b'000000064718.jpg'\n",
      "b'000000015497.jpg'\n",
      "b'000000486573.jpg'\n",
      "b'000000439525.jpg'\n",
      "b'000000196185.jpg'b'000000481390.jpg'\n",
      "\n",
      "b'000000036539.jpg'\n",
      "b'000000232088.jpg'\n",
      "b'000000529148.jpg'\n",
      "b'000000257169.jpg'\n",
      "b'000000185250.jpg'\n",
      "b'000000351609.jpg'\n",
      "b'000000364322.jpg'\n",
      "b'000000154718.jpg'\n",
      "b'000000199055.jpg'\n",
      "b'000000483050.jpg'\n",
      "b'000000234607.jpg'\n",
      "b'000000374083.jpg'\n",
      "b'000000163951.jpg'\n",
      "b'000000218249.jpg'\n",
      "b'000000226662.jpg'\n",
      "b'000000350019.jpg'\n",
      "b'000000236730.jpg'\n",
      "b'000000091779.jpg'\n",
      "b'000000307074.jpg'\n",
      "b'000000423971.jpg'\n",
      "b'000000515828.jpg'\n",
      "b'000000157847.jpg'\n",
      "b'000000121744.jpg'\n",
      "b'000000213593.jpg'\n",
      "b'000000086220.jpg'\n",
      "b'000000061418.jpg'\n",
      "b'000000434548.jpg'\n",
      "b'000000268375.jpg'\n",
      "b'000000319617.jpg'\n",
      "b'000000212559.jpg'\n",
      "b'000000426795.jpg'\n",
      "b'000000438955.jpg'\n",
      "b'000000099053.jpg'\n",
      "b'000000319369.jpg'\n",
      "b'000000353096.jpg'\n",
      "b'000000179653.jpg'\n",
      "b'000000159791.jpg'\n",
      "b'000000149622.jpg'\n",
      "b'000000293324.jpg'\n",
      "b'000000345252.jpg'\n",
      "b'000000179765.jpg'\n",
      "b'000000283268.jpg'\n",
      "b'000000326128.jpg'\n",
      "b'000000283318.jpg'\n",
      "b'000000540466.jpg'\n",
      "b'000000550322.jpg'\n",
      "b'000000235399.jpg'\n",
      "b'000000528705.jpg'\n",
      "b'000000132544.jpg'\n",
      "b'000000119677.jpg'\n",
      "b'000000305317.jpg'\n",
      "b'000000030504.jpg'\n",
      "b'000000288391.jpg'\n",
      "b'000000482800.jpg'\n",
      "b'000000099242.jpg'\n",
      "b'000000025181.jpg'\n",
      "b'000000368900.jpg'\n",
      "b'000000154087.jpg'\n",
      "b'000000209530.jpg'\n",
      "b'000000441491.jpg'\n",
      "b'000000565597.jpg'\n",
      "b'000000085329.jpg'\n",
      "b'000000541773.jpg'\n",
      "b'000000159399.jpg'\n",
      "b'000000511321.jpg'\n",
      "b'000000386134.jpg'\n",
      "b'000000244750.jpg'\n",
      "b'000000562443.jpg'\n",
      "b'000000415748.jpg'\n",
      "b'000000552842.jpg'\n",
      "b'000000160772.jpg'\n",
      "b'000000112798.jpg'\n",
      "b'000000526256.jpg'\n",
      "b'000000118367.jpg'\n",
      "b'000000145591.jpg'\n",
      "b'000000210520.jpg'\n",
      "b'000000265816.jpg'\n",
      "b'000000393469.jpg'\n",
      "b'000000024567.jpg'\n",
      "b'000000214539.jpg'\n",
      "b'000000331604.jpg'\n",
      "b'000000439290.jpg'\n",
      "b'000000320425.jpg'\n",
      "b'000000577539.jpg'\n",
      "b'000000212895.jpg'\n",
      "b'000000470952.jpg'\n",
      "b'000000415716.jpg'\n",
      "b'000000061658.jpg'\n",
      "b'000000082696.jpg'\n",
      "b'000000495146.jpg'\n",
      "b'000000025593.jpg'\n",
      "b'000000453166.jpg'\n",
      "b'000000415990.jpg'\n",
      "b'000000528862.jpg'\n",
      "b'000000052591.jpg'\n",
      "b'000000085195.jpg'\n",
      "b'000000119911.jpg'\n",
      "b'000000136772.jpg'\n",
      "b'000000233370.jpg'\n",
      "b'000000021503.jpg'\n",
      "b'000000030494.jpg'\n",
      "b'000000517056.jpg'\n",
      "b'000000152771.jpg'\n",
      "b'000000078959.jpg'\n",
      "b'000000352618.jpg'\n",
      "b'000000107554.jpg'\n",
      "b'000000497867.jpg'\n",
      "b'000000162130.jpg'\n",
      "b'000000119088.jpg'\n",
      "b'000000111086.jpg'b'000000227765.jpg'\n",
      "\n",
      "b'000000047740.jpg'\n",
      "b'000000308394.jpg'\n",
      "b'000000486438.jpg'\n",
      "b'000000404678.jpg'\n",
      "b'000000363666.jpg'\n",
      "b'000000177539.jpg'\n",
      "b'000000187055.jpg'\n",
      "b'000000187236.jpg'\n",
      "b'000000384949.jpg'\n",
      "b'000000164363.jpg'\n",
      "b'000000181816.jpg'\n",
      "b'000000160864.jpg'\n",
      "b'000000165681.jpg'\n",
      "b'000000097988.jpg'\n",
      "b'000000214720.jpg'\n",
      "b'000000149406.jpg'\n",
      "b'000000415882.jpg'\n",
      "b'000000470924.jpg'\n",
      "b'000000038576.jpg'\n",
      "b'000000169076.jpg'\n",
      "b'000000458223.jpg'\n",
      "b'000000185802.jpg'\n",
      "b'000000344059.jpg'\n",
      "b'000000161642.jpg'\n",
      "b'000000485071.jpg'\n",
      "b'000000293200.jpg'b'000000354072.jpg'\n",
      "\n",
      "b'000000024144.jpg'\n",
      "b'000000176799.jpg'\n",
      "b'000000296231.jpg'\n",
      "b'000000369442.jpg'\n",
      "b'000000365766.jpg'\n",
      "b'000000133969.jpg'\n",
      "b'000000319696.jpg'\n",
      "b'000000391722.jpg'\n",
      "b'000000564133.jpg'\n",
      "b'000000542776.jpg'\n",
      "b'000000100283.jpg'\n",
      "b'000000229753.jpg'\n",
      "b'000000516173.jpg'\n",
      "b'000000366199.jpg'\n",
      "b'000000301135.jpg'\n",
      "b'000000047828.jpg'\n",
      "b'000000340272.jpg'\n",
      "b'000000578236.jpg'\n",
      "b'000000322944.jpg'\n",
      "b'000000110359.jpg'\n",
      "b'000000234807.jpg'\n",
      "b'000000482487.jpg'\n",
      "b'000000050145.jpg'\n",
      "b'000000553776.jpg'\n",
      "b'000000556765.jpg'\n",
      "b'000000341196.jpg'\n",
      "b'000000580757.jpg'\n",
      "b'000000140439.jpg'\n",
      "b'000000485972.jpg'\n",
      "b'000000236599.jpg'\n",
      "b'000000261706.jpg'\n",
      "100\n",
      " [!] Load failed...\n",
      "b'000000221281.jpg'\n",
      "b'000000226662.jpg'\n",
      "b'000000447187.jpg'\n",
      "b'000000348708.jpg'\n",
      "b'000000050679.jpg'\n",
      "b'000000170613.jpg'\n",
      "b'000000509656.jpg'\n",
      "b'000000117914.jpg'\n",
      "b'000000183127.jpg'\n",
      "b'000000229849.jpg'\n",
      "step 0, loss 120972, focal_loss 241941, pull_loss 0.274181, push_loss 0.0421837, offset_loss 3.13306, time 21.4869, lr 0.00025\n",
      "b'000000317433.jpg'\n",
      "b'000000546829.jpg'\n",
      "b'000000177935.jpg'\n",
      "b'000000535858.jpg'\n",
      "b'000000297085.jpg'\n",
      "b'000000284445.jpg'\n",
      "b'000000307658.jpg'\n",
      "b'000000278705.jpg'\n",
      "b'000000049810.jpg'\n",
      "b'000000494913.jpg'\n",
      "b'000000357978.jpg'\n",
      "b'000000511076.jpg'\n",
      "b'000000341973.jpg'\n",
      "b'000000163155.jpg'\n",
      "b'000000285894.jpg'\n",
      "step 1, loss 62255.1, focal_loss 124504, pull_loss 1.51955, push_loss 0.0271627, offset_loss 4.91533, time 5.48376, lr 0.00025\n",
      "b'000000147338.jpg'\n",
      "b'000000297084.jpg'\n",
      "b'000000224093.jpg'\n",
      "b'000000415194.jpg'\n",
      "b'000000261712.jpg'\n",
      "b'000000183246.jpg'\n",
      "b'000000221502.jpg'\n",
      "b'000000014831.jpg'\n",
      "b'000000213086.jpg'\n",
      "b'000000369037.jpg'\n",
      "step 2, loss 57923.7, focal_loss 115845, pull_loss 0.24248, push_loss 0.0330621, offset_loss 1.98243, time 5.49073, lr 0.00025\n",
      "b'000000201646.jpg'\n",
      "b'000000546964.jpg'\n",
      "b'000000105912.jpg'\n",
      "b'000000110784.jpg'\n",
      "b'000000009448.jpg'\n",
      "b'000000323151.jpg'\n",
      "b'000000321333.jpg'\n",
      "b'000000269121.jpg'\n",
      "b'000000515350.jpg'\n",
      "b'000000502136.jpg'\n",
      "step 3, loss 46198.6, focal_loss 92395.2, pull_loss 0.243833, push_loss 0.0662163, offset_loss 1.63759, time 5.49655, lr 0.00025\n",
      "b'000000466416.jpg'\n",
      "b'000000221754.jpg'\n",
      "b'000000017714.jpg'\n",
      "b'000000262048.jpg'\n",
      "b'000000456662.jpg'\n",
      "b'000000152740.jpg'\n",
      "b'000000153529.jpg'\n",
      "b'000000386912.jpg'\n",
      "b'000000024919.jpg'\n",
      "b'000000341469.jpg'\n",
      "step 4, loss 27890.7, focal_loss 55778.2, pull_loss 1.07166, push_loss 0.0314801, offset_loss 2.08189, time 5.5454, lr 0.00025\n",
      "b'000000434548.jpg'\n",
      "b'000000396903.jpg'\n",
      "b'000000570736.jpg'\n",
      "b'000000284282.jpg'\n",
      "b'000000348045.jpg'\n",
      "b'000000261161.jpg'\n",
      "b'000000097585.jpg'\n",
      "b'000000395575.jpg'\n",
      "b'000000329219.jpg'\n",
      "b'000000561335.jpg'\n",
      "step 5, loss 61732.4, focal_loss 123464, pull_loss 0.116804, push_loss 0.0634239, offset_loss 0.991816, time 5.52547, lr 0.00025\n",
      "b'000000562121.jpg'\n",
      "b'000000410735.jpg'\n",
      "b'000000446117.jpg'\n",
      "b'000000206025.jpg'\n",
      "b'000000312720.jpg'\n",
      "b'000000493772.jpg'\n",
      "b'000000385029.jpg'\n",
      "b'000000087470.jpg'\n",
      "b'000000253835.jpg'\n",
      "b'000000015254.jpg'\n",
      "step 6, loss 34643, focal_loss 69284.4, pull_loss 0.100195, push_loss 0.0341936, offset_loss 1.454, time 5.61325, lr 0.00025\n",
      "b'000000448448.jpg'\n",
      "b'000000494869.jpg'\n",
      "b'000000194724.jpg'\n",
      "b'000000138819.jpg'\n",
      "b'000000241677.jpg'\n",
      "b'000000294855.jpg'\n",
      "b'000000427034.jpg'\n",
      "b'000000355240.jpg'\n",
      "b'000000258793.jpg'\n",
      "b'000000284698.jpg'\n",
      "step 7, loss 16475.5, focal_loss 32948.6, pull_loss 0.429521, push_loss 0.0469638, offset_loss 1.96894, time 5.61945, lr 0.00025\n",
      "b'000000271471.jpg'\n",
      "b'000000338718.jpg'\n",
      "b'000000129054.jpg'\n",
      "b'000000167540.jpg'\n",
      "b'000000280930.jpg'\n",
      "b'000000125572.jpg'\n",
      "b'000000547854.jpg'\n",
      "b'000000305343.jpg'\n",
      "b'000000263299.jpg'\n",
      "b'000000507223.jpg'\n",
      "step 8, loss 23700.4, focal_loss 47399.7, pull_loss 0.201939, push_loss 0.0345211, offset_loss 0.900354, time 5.68624, lr 0.00025\n",
      "b'000000568439.jpg'\n",
      "b'000000576955.jpg'\n",
      "b'000000553990.jpg'\n",
      "b'000000366141.jpg'\n",
      "b'000000579818.jpg'\n",
      "b'000000540280.jpg'\n",
      "b'000000243989.jpg'\n",
      "b'000000324818.jpg'\n",
      "b'000000429109.jpg'\n",
      "b'000000232088.jpg'\n",
      "step 9, loss 10403.7, focal_loss 20803.3, pull_loss 1.14042, push_loss 0.0343742, offset_loss 2.89417, time 5.72563, lr 0.00025\n",
      "b'000000119365.jpg'\n",
      "b'000000316666.jpg'\n",
      "b'000000189226.jpg'\n",
      "b'000000538364.jpg'\n",
      "b'000000015751.jpg'\n",
      "b'000000521259.jpg'\n",
      "b'000000146358.jpg'\n",
      "b'000000064868.jpg'\n",
      "b'000000327306.jpg'\n",
      "b'000000142971.jpg'\n",
      "step 10, loss 7347.92, focal_loss 14694.7, pull_loss 0.0788658, push_loss 0.0600556, offset_loss 1.00904, time 5.7636, lr 0.00025\n",
      "b'000000243204.jpg'\n",
      "b'000000194506.jpg'\n",
      "b'000000500257.jpg'\n",
      "b'000000292082.jpg'\n",
      "b'000000058705.jpg'\n",
      "b'000000435003.jpg'\n",
      "b'000000155051.jpg'\n",
      "b'000000557916.jpg'\n",
      "b'000000153011.jpg'\n",
      "b'000000319369.jpg'\n",
      "b'000000211042.jpg'\n",
      "b'000000134112.jpg'\n",
      "b'000000040471.jpg'\n",
      "b'000000001296.jpg'\n",
      "b'000000203389.jpg'\n",
      "step 11, loss 3814.85, focal_loss 7628.51, pull_loss 0.0502929, push_loss 0.0477384, offset_loss 1.0924, time 5.76368, lr 0.00025\n",
      "b'000000499266.jpg'b'000000090003.jpg'\n",
      "\n",
      "b'000000137950.jpg'\n",
      "b'000000427338.jpg'\n",
      "b'000000080671.jpg'\n",
      "b'000000035062.jpg'\n",
      "b'000000033005.jpg'\n",
      "b'000000413552.jpg'\n",
      "b'000000007281.jpg'\n",
      "b'000000345466.jpg'\n",
      "step 12, loss 2656.83, focal_loss 5312.47, pull_loss 0.151131, push_loss 0.0560412, offset_loss 0.995266, time 5.81678, lr 0.00025\n",
      "b'000000093965.jpg'\n",
      "b'000000173091.jpg'\n",
      "b'000000163290.jpg'\n",
      "b'000000529939.jpg'\n",
      "b'000000369323.jpg'\n",
      "b'000000577149.jpg'\n",
      "b'000000013004.jpg'\n",
      "b'000000184384.jpg'\n",
      "b'000000485071.jpg'\n",
      "b'000000213224.jpg'\n",
      "step 13, loss 4972.97, focal_loss 9944.89, pull_loss 0.0788774, push_loss 0.0369936, offset_loss 0.933371, time 5.69401, lr 0.00025\n",
      "b'000000299553.jpg'\n",
      "b'000000491071.jpg'\n",
      "b'000000079188.jpg'\n",
      "b'000000127135.jpg'\n",
      "b'000000311392.jpg'\n",
      "b'000000340015.jpg'\n",
      "b'000000337987.jpg'\n",
      "b'000000356424.jpg'\n",
      "b'000000571718.jpg'\n",
      "b'000000434230.jpg'\n",
      "step 14, loss 2122.14, focal_loss 4242.7, pull_loss 0.26604, push_loss 0.0516346, offset_loss 1.26108, time 5.70578, lr 0.00025\n",
      "b'000000227187.jpg'\n",
      "b'000000384616.jpg'\n",
      "b'000000395633.jpg'\n",
      "b'000000320706.jpg'\n",
      "b'000000434297.jpg'\n",
      "b'000000395180.jpg'b'000000038829.jpg'\n",
      "\n",
      "b'000000442822.jpg'\n",
      "b'000000060449.jpg'\n",
      "b'000000275791.jpg'\n",
      "step 15, loss 1573.89, focal_loss 3146.81, pull_loss 0.129307, push_loss 0.0503221, offset_loss 0.779757, time 5.65626, lr 0.00025\n",
      "b'000000422670.jpg'\n",
      "b'000000085665.jpg'\n",
      "b'000000148508.jpg'\n",
      "b'000000340175.jpg'\n",
      "b'000000119641.jpg'\n",
      "b'000000261535.jpg'\n",
      "b'000000184324.jpg'\n",
      "b'000000461751.jpg'\n",
      "b'000000213171.jpg'\n",
      "b'000000034452.jpg'\n",
      "step 16, loss 2465.88, focal_loss 4930.73, pull_loss 0.101231, push_loss 0.0375223, offset_loss 0.894272, time 5.62489, lr 0.00025\n",
      "b'000000172396.jpg'\n",
      "b'000000143931.jpg'\n",
      "b'000000246454.jpg'\n",
      "b'000000550797.jpg'\n",
      "b'000000047121.jpg'\n",
      "b'000000391290.jpg'\n",
      "b'000000563603.jpg'\n",
      "b'000000122672.jpg'\n",
      "b'000000210030.jpg'\n",
      "b'000000405205.jpg'\n",
      "step 17, loss 1813.93, focal_loss 3626.97, pull_loss 0.0756219, push_loss 0.0444952, offset_loss 0.763094, time 5.66286, lr 0.00025\n",
      "b'000000001000.jpg'\n",
      "b'000000132375.jpg'\n",
      "b'000000308466.jpg'\n",
      "b'000000322163.jpg'\n",
      "b'000000083172.jpg'\n",
      "b'000000530162.jpg'\n",
      "b'000000419201.jpg'\n",
      "b'000000011760.jpg'\n",
      "b'000000227478.jpg'\n",
      "b'000000153510.jpg'\n",
      "step 18, loss 427.098, focal_loss 853.427, pull_loss 0.0609486, push_loss 0.0524622, offset_loss 0.655214, time 5.5897, lr 0.00025\n",
      "b'000000224807.jpg'\n",
      "b'000000092124.jpg'\n",
      "b'000000395343.jpg'\n",
      "b'000000286553.jpg'\n",
      "b'000000154705.jpg'\n",
      "b'000000266981.jpg'\n",
      "b'000000483667.jpg'\n",
      "b'000000290293.jpg'\n",
      "b'000000014380.jpg'\n",
      "b'000000396338.jpg'\n",
      "step 19, loss 261.889, focal_loss 522.807, pull_loss 0.0242239, push_loss 0.0610738, offset_loss 0.88448, time 5.61888, lr 0.00025\n",
      "b'000000414170.jpg'\n",
      "b'000000023899.jpg'\n",
      "b'000000147223.jpg'\n",
      "b'000000124636.jpg'\n",
      "b'000000169356.jpg'\n",
      "b'000000236730.jpg'\n",
      "b'000000330369.jpg'\n",
      "b'000000104198.jpg'\n",
      "b'000000335529.jpg'\n",
      "b'000000368038.jpg'\n",
      "step 20, loss 327.966, focal_loss 654.792, pull_loss 0.0312591, push_loss 0.111933, offset_loss 0.99656, time 5.62067, lr 0.00025\n",
      "b'000000191580.jpg'\n",
      "b'000000165039.jpg'\n",
      "b'000000111179.jpg'\n",
      "b'000000573258.jpg'\n",
      "b'000000479126.jpg'\n",
      "b'000000372203.jpg'\n",
      "b'000000193181.jpg'\n",
      "b'000000431727.jpg'\n",
      "b'000000143556.jpg'\n",
      "b'000000384136.jpg'\n",
      "b'000000500716.jpg'\n",
      "b'000000417085.jpg'\n",
      "b'000000001675.jpg'\n",
      "b'000000269196.jpg'\n",
      "b'000000018519.jpg'\n",
      "step 21, loss 163.73, focal_loss 326.644, pull_loss 0.0381332, push_loss 0.0463281, offset_loss 0.73154, time 5.60499, lr 0.00025\n",
      "b'000000544306.jpg'\n",
      "b'000000457884.jpg'\n",
      "b'000000350003.jpg'\n",
      "b'000000519039.jpg'\n",
      "b'000000142472.jpg'\n",
      "b'000000513580.jpg'\n",
      "b'000000036660.jpg'\n",
      "b'000000124277.jpg'\n",
      "b'000000315219.jpg'\n",
      "b'000000474039.jpg'\n",
      "step 22, loss 184.988, focal_loss 369.298, pull_loss 0.0696657, push_loss 0.0553579, offset_loss 0.554143, time 5.65293, lr 0.00025\n",
      "b'000000272049.jpg'\n",
      "b'000000172595.jpg'\n",
      "b'000000465180.jpg'\n",
      "b'000000363840.jpg'\n",
      "b'000000483999.jpg'\n",
      "b'000000302760.jpg'\n",
      "b'000000279145.jpg'\n",
      "b'000000377497.jpg'\n",
      "b'000000167240.jpg'\n",
      "b'000000323263.jpg'\n",
      "step 23, loss 98.3387, focal_loss 195.919, pull_loss 0.107817, push_loss 0.055389, offset_loss 0.594598, time 5.65053, lr 0.00025\n",
      "b'000000472030.jpg'\n",
      "b'000000417632.jpg'\n",
      "b'000000522751.jpg'\n",
      "b'000000453341.jpg'\n",
      "b'000000488710.jpg'\n",
      "b'000000099024.jpg'\n",
      "b'000000067406.jpg'\n",
      "b'000000448365.jpg'\n",
      "b'000000351362.jpg'\n",
      "b'000000356531.jpg'\n",
      "step 24, loss 141.25, focal_loss 281.663, pull_loss 0.0907411, push_loss 0.0817681, offset_loss 0.664153, time 5.67765, lr 0.00025\n",
      "b'000000286908.jpg'\n",
      "b'000000026465.jpg'\n",
      "b'000000368212.jpg'\n",
      "b'000000451714.jpg'\n",
      "b'000000384666.jpg'\n",
      "b'000000217614.jpg'\n",
      "b'000000378454.jpg'\n",
      "b'000000552371.jpg'\n",
      "b'000000149222.jpg'\n",
      "b'000000206838.jpg'\n",
      "step 25, loss 129.434, focal_loss 258.141, pull_loss 0.0466145, push_loss 0.0460672, offset_loss 0.634292, time 5.70555, lr 0.00025\n",
      "b'000000189828.jpg'\n",
      "b'000000460929.jpg'\n",
      "b'000000384661.jpg'\n",
      "b'000000031620.jpg'\n",
      "b'000000022371.jpg'\n",
      "b'000000009914.jpg'\n",
      "b'000000308799.jpg'\n",
      "b'000000044068.jpg'\n",
      "b'000000411817.jpg'\n",
      "b'000000174018.jpg'\n",
      "step 26, loss 91.0362, focal_loss 181.334, pull_loss 0.0173921, push_loss 0.0481655, offset_loss 0.672783, time 5.6634, lr 0.00025\n",
      "b'000000536947.jpg'\n",
      "b'000000071756.jpg'\n",
      "b'000000446703.jpg'\n",
      "b'000000424162.jpg'\n",
      "b'000000179642.jpg'\n",
      "b'000000495146.jpg'\n",
      "b'000000041888.jpg'\n",
      "b'000000455085.jpg'\n",
      "b'000000345941.jpg'\n",
      "b'000000323571.jpg'\n",
      "step 27, loss 100.506, focal_loss 200.292, pull_loss 0.0252253, push_loss 0.0632579, offset_loss 0.630889, time 5.70199, lr 0.00025\n",
      "b'000000551304.jpg'\n",
      "b'000000265518.jpg'\n",
      "b'000000482719.jpg'\n",
      "b'000000230450.jpg'\n",
      "b'000000535608.jpg'\n",
      "b'000000375493.jpg'b'000000243495.jpg'\n",
      "\n",
      "b'000000035326.jpg'\n",
      "b'000000162858.jpg'\n",
      "b'000000297681.jpg'\n",
      "step 28, loss 55.4584, focal_loss 110.144, pull_loss 0.0300047, push_loss 0.0862063, offset_loss 0.65615, time 5.68395, lr 0.00025\n",
      "b'000000270883.jpg'\n",
      "b'000000002431.jpg'\n",
      "b'000000343149.jpg'\n",
      "b'000000383339.jpg'\n",
      "b'000000563758.jpg'\n",
      "b'000000006763.jpg'\n",
      "b'000000187249.jpg'\n",
      "b'000000365521.jpg'\n",
      "b'000000346707.jpg'\n",
      "b'000000132796.jpg'\n",
      "step 29, loss 69.8687, focal_loss 139.24, pull_loss 0.0208211, push_loss 0.0387565, offset_loss 0.437688, time 5.62119, lr 0.00025\n",
      "b'000000289229.jpg'b'000000172571.jpg'\n",
      "\n",
      "b'000000347335.jpg'\n",
      "b'000000342367.jpg'\n",
      "b'000000161781.jpg'\n",
      "b'000000491464.jpg'\n",
      "b'000000537802.jpg'\n",
      "b'000000333956.jpg'\n",
      "b'000000323202.jpg'\n",
      "b'000000118921.jpg'\n",
      "step 30, loss 78.7524, focal_loss 156.855, pull_loss 0.0638653, push_loss 0.0355713, offset_loss 0.550719, time 5.62652, lr 0.00025\n",
      "b'000000046804.jpg'b'000000486438.jpg'\n",
      "\n",
      "b'000000235784.jpg'\n",
      "b'000000073326.jpg'\n",
      "b'000000368961.jpg'\n",
      "b'000000283520.jpg'\n",
      "b'000000486040.jpg'\n",
      "b'000000369442.jpg'\n",
      "b'000000469828.jpg'\n",
      "b'000000359219.jpg'\n",
      "b'000000201418.jpg'\n",
      "b'000000170116.jpg'\n",
      "b'000000544444.jpg'\n",
      "b'000000384949.jpg'\n",
      "b'000000261116.jpg'\n",
      "step 31, loss 73.7972, focal_loss 146.839, pull_loss 0.0756133, push_loss 0.0453942, offset_loss 0.634824, time 5.66532, lr 0.00025\n",
      "b'000000286849.jpg'\n",
      "b'000000480842.jpg'\n",
      "b'000000396526.jpg'\n",
      "b'000000147415.jpg'\n",
      "b'000000210388.jpg'\n",
      "b'000000244411.jpg'\n",
      "b'000000019109.jpg'\n",
      "b'000000564023.jpg'\n",
      "b'000000079014.jpg'\n",
      "b'000000251140.jpg'\n",
      "step 32, loss 44.048, focal_loss 87.48, pull_loss 0.0353252, push_loss 0.0460031, offset_loss 0.534745, time 5.63156, lr 0.00025\n",
      "b'000000343453.jpg'\n",
      "b'000000226984.jpg'\n",
      "b'000000334521.jpg'\n",
      "b'000000016249.jpg'\n",
      "b'000000504415.jpg'\n",
      "b'000000084752.jpg'\n",
      "b'000000125778.jpg'\n",
      "b'000000451879.jpg'\n",
      "b'000000295478.jpg'\n",
      "b'000000380913.jpg'\n",
      "step 33, loss 69.0889, focal_loss 137.452, pull_loss 0.0564969, push_loss 0.0504232, offset_loss 0.619253, time 5.66171, lr 0.00025\n",
      "b'000000245311.jpg'\n",
      "b'000000144706.jpg'\n",
      "b'000000140556.jpg'\n",
      "b'000000257896.jpg'\n",
      "b'000000408774.jpg'\n",
      "b'000000563470.jpg'\n",
      "b'000000428280.jpg'\n",
      "b'000000394275.jpg'\n",
      "b'000000193429.jpg'\n",
      "b'000000315492.jpg'\n",
      "step 34, loss 65.2341, focal_loss 129.819, pull_loss 0.0364458, push_loss 0.092701, offset_loss 0.519907, time 5.68484, lr 0.00025\n",
      "b'000000075456.jpg'\n",
      "b'000000199977.jpg'\n",
      "b'000000560266.jpg'\n",
      "b'000000262487.jpg'\n",
      "b'000000023272.jpg'\n",
      "b'000000540932.jpg'\n",
      "b'000000214869.jpg'\n",
      "b'000000109055.jpg'\n",
      "b'000000105264.jpg'\n",
      "b'000000492905.jpg'\n",
      "step 35, loss 34.7499, focal_loss 68.8825, pull_loss 0.0296913, push_loss 0.0504262, offset_loss 0.537292, time 5.57417, lr 0.00025\n",
      "b'000000571893.jpg'\n",
      "b'000000166509.jpg'\n",
      "b'000000149406.jpg'\n",
      "b'000000427160.jpg'\n",
      "b'000000273617.jpg'\n",
      "b'000000415990.jpg'\n",
      "b'000000343706.jpg'\n",
      "b'000000161008.jpg'\n",
      "b'000000479953.jpg'\n",
      "b'000000546717.jpg'\n",
      "step 36, loss 30.0054, focal_loss 59.3, pull_loss 0.0217515, push_loss 0.0737294, offset_loss 0.615246, time 5.64036, lr 0.00025\n",
      "b'000000367228.jpg'\n",
      "b'000000403565.jpg'\n",
      "b'000000437898.jpg'\n",
      "b'000000478286.jpg'\n",
      "b'000000457559.jpg'\n",
      "b'000000017182.jpg'\n",
      "b'000000094751.jpg'\n",
      "b'000000002532.jpg'\n",
      "b'000000069224.jpg'\n",
      "b'000000110972.jpg'\n",
      "step 37, loss 55.2197, focal_loss 109.829, pull_loss 0.0117485, push_loss 0.0461107, offset_loss 0.552218, time 5.68227, lr 0.00025\n",
      "b'000000297595.jpg'\n",
      "b'000000077396.jpg'\n",
      "b'000000411953.jpg'\n",
      "b'000000013348.jpg'\n",
      "b'000000007816.jpg'\n",
      "b'000000542127.jpg'\n",
      "b'000000429623.jpg'\n",
      "b'000000178618.jpg'\n",
      "b'000000309467.jpg'\n",
      "b'000000091615.jpg'\n",
      "step 38, loss 40.0184, focal_loss 79.5483, pull_loss 0.0284532, push_loss 0.0376599, offset_loss 0.422276, time 5.61652, lr 0.00025\n",
      "b'000000017959.jpg'\n",
      "b'000000090891.jpg'\n",
      "b'000000453708.jpg'\n",
      "b'000000257169.jpg'\n",
      "b'000000533855.jpg'\n",
      "b'000000430286.jpg'\n",
      "b'000000401250.jpg'\n",
      "b'000000179265.jpg'\n",
      "b'000000463283.jpg'\n",
      "b'000000235057.jpg'\n",
      "step 39, loss 38.1835, focal_loss 75.8469, pull_loss 0.0222651, push_loss 0.0589138, offset_loss 0.438963, time 5.65319, lr 0.00025\n",
      "b'000000015597.jpg'\n",
      "b'000000188465.jpg'\n",
      "b'000000017029.jpg'\n",
      "b'000000540962.jpg'\n",
      "b'000000068933.jpg'\n",
      "b'000000399205.jpg'\n",
      "b'000000048924.jpg'\n",
      "b'000000263068.jpg'\n",
      "b'000000267169.jpg'\n",
      "b'000000488592.jpg'\n",
      "step 40, loss 27.4893, focal_loss 54.3219, pull_loss 0.0387995, push_loss 0.0557792, offset_loss 0.562216, time 5.65256, lr 0.00025\n",
      "b'000000306437.jpg'\n",
      "b'000000045596.jpg'\n",
      "b'000000125211.jpg'\n",
      "b'000000555050.jpg'\n",
      "b'000000226592.jpg'\n",
      "b'000000392722.jpg'\n",
      "b'000000297562.jpg'\n",
      "b'000000433103.jpg'\n",
      "b'000000201775.jpg'\n",
      "b'000000227491.jpg'\n",
      "b'000000523782.jpg'\n",
      "b'000000579158.jpg'\n",
      "b'000000337055.jpg'\n",
      "b'000000248334.jpg'\n",
      "b'000000312421.jpg'\n",
      "step 41, loss 30.9009, focal_loss 61.1926, pull_loss 0.0311512, push_loss 0.0539854, offset_loss 0.524047, time 5.67178, lr 0.00025\n",
      "b'000000230362.jpg'\n",
      "b'000000197388.jpg'\n",
      "b'000000382030.jpg'\n",
      "b'000000076625.jpg'\n",
      "b'000000243344.jpg'\n",
      "b'000000365098.jpg'\n",
      "b'000000286994.jpg'\n",
      "b'000000024610.jpg'\n",
      "b'000000018491.jpg'\n",
      "b'000000101022.jpg'\n",
      "step 42, loss 31.9289, focal_loss 63.3112, pull_loss 0.0111009, push_loss 0.0669453, offset_loss 0.468476, time 5.65253, lr 0.00025\n",
      "b'000000263425.jpg'\n",
      "b'000000011122.jpg'\n",
      "b'000000178982.jpg'\n",
      "b'000000154644.jpg'\n",
      "b'000000559160.jpg'\n",
      "b'000000231747.jpg'b'000000474881.jpg'\n",
      "\n",
      "b'000000393056.jpg'\n",
      "b'000000147740.jpg'\n",
      "b'000000268729.jpg'\n",
      "step 43, loss 37.7245, focal_loss 74.9591, pull_loss 0.0206947, push_loss 0.0466454, offset_loss 0.422564, time 5.69905, lr 0.00025\n",
      "b'000000394510.jpg'\n",
      "b'000000249786.jpg'\n",
      "b'000000330818.jpg'\n",
      "b'000000350679.jpg'\n",
      "b'000000249643.jpg'\n",
      "b'000000010583.jpg'\n",
      "b'000000096960.jpg'\n",
      "b'000000437331.jpg'\n",
      "b'000000095899.jpg'\n",
      "b'000000300913.jpg'\n",
      "step 44, loss 33.8803, focal_loss 67.2396, pull_loss 0.010707, push_loss 0.0505217, offset_loss 0.459652, time 5.66823, lr 0.00025\n",
      "b'000000107087.jpg'\n",
      "b'000000409424.jpg'\n",
      "b'000000520009.jpg'\n",
      "b'000000206411.jpg'\n",
      "b'000000041635.jpg'\n",
      "b'000000017207.jpg'\n",
      "b'000000070254.jpg'\n",
      "b'000000325347.jpg'\n",
      "b'000000038825.jpg'\n",
      "b'000000556000.jpg'\n",
      "step 45, loss 19.5734, focal_loss 38.5755, pull_loss 0.0254317, push_loss 0.0430082, offset_loss 0.50279, time 5.66687, lr 0.00025\n",
      "b'000000192670.jpg'\n",
      "b'000000051309.jpg'\n",
      "b'000000120572.jpg'\n",
      "b'000000521052.jpg'\n",
      "b'000000172649.jpg'\n",
      "b'000000025394.jpg'\n",
      "b'000000479155.jpg'\n",
      "b'000000335427.jpg'\n",
      "b'000000291490.jpg'\n",
      "b'000000437239.jpg'\n",
      "step 46, loss 23.9678, focal_loss 47.4359, pull_loss 0.0182013, push_loss 0.0372531, offset_loss 0.444219, time 5.69321, lr 0.00025\n",
      "b'000000162092.jpg'\n",
      "b'000000118594.jpg'\n",
      "b'000000556193.jpg'\n",
      "b'000000144003.jpg'\n",
      "b'000000424349.jpg'\n",
      "b'000000313130.jpg'\n",
      "b'000000367818.jpg'\n",
      "b'000000467511.jpg'\n",
      "b'000000311928.jpg'\n",
      "b'000000138954.jpg'\n",
      "step 47, loss 21.434, focal_loss 42.321, pull_loss 0.021359, push_loss 0.0804816, offset_loss 0.44523, time 5.69126, lr 0.00025\n",
      "b'000000520301.jpg'\n",
      "b'000000397303.jpg'\n",
      "b'000000094185.jpg'\n",
      "b'000000316054.jpg'\n",
      "b'000000418961.jpg'\n",
      "b'000000513688.jpg'\n",
      "b'000000517687.jpg'\n",
      "b'000000365208.jpg'\n",
      "b'000000053994.jpg'\n",
      "b'000000110449.jpg'\n",
      "step 48, loss 25.8529, focal_loss 51.1635, pull_loss 0.0166246, push_loss 0.0573422, offset_loss 0.468247, time 5.68791, lr 0.00025\n",
      "b'000000376478.jpg'\n",
      "b'000000336658.jpg'\n",
      "b'000000370375.jpg'\n",
      "b'000000114907.jpg'\n",
      "b'000000286708.jpg'\n",
      "b'000000172547.jpg'\n",
      "b'000000220584.jpg'\n",
      "b'000000088432.jpg'\n",
      "b'000000093154.jpg'\n",
      "b'000000365095.jpg'\n",
      "step 49, loss 19.7497, focal_loss 39.0661, pull_loss 0.0186346, push_loss 0.0423057, offset_loss 0.372324, time 5.63745, lr 0.00025\n",
      "b'000000322895.jpg'\n",
      "b'000000086483.jpg'\n",
      "b'000000225670.jpg'\n",
      "b'000000097994.jpg'\n",
      "b'000000111036.jpg'\n",
      "b'000000262227.jpg'\n",
      "b'000000277020.jpg'\n",
      "b'000000228144.jpg'\n",
      "b'000000152870.jpg'\n",
      "b'000000485237.jpg'\n",
      "step 50, loss 26.6401, focal_loss 52.8449, pull_loss 0.0176623, push_loss 0.0930792, offset_loss 0.324615, time 5.62825, lr 0.00025\n",
      "b'000000227898.jpg'b'000000126216.jpg'\n",
      "\n",
      "b'000000442161.jpg'\n",
      "b'000000320743.jpg'\n",
      "b'000000387916.jpg'\n",
      "b'000000311081.jpg'\n",
      "b'000000392933.jpg'\n",
      "b'000000192964.jpg'\n",
      "b'000000204329.jpg'\n",
      "b'000000061658.jpg'\n",
      "b'000000182923.jpg'\n",
      "b'000000228436.jpg'\n",
      "b'000000341719.jpg'\n",
      "b'000000221017.jpg'\n",
      "b'000000117374.jpg'\n",
      "step 51, loss 19.765, focal_loss 39.0202, pull_loss 0.013962, push_loss 0.0528489, offset_loss 0.443014, time 5.62868, lr 0.00025\n",
      "b'000000422998.jpg'\n",
      "b'000000034417.jpg'\n",
      "b'000000167122.jpg'\n",
      "b'000000325483.jpg'\n",
      "b'000000173004.jpg'\n",
      "b'000000236784.jpg'b'000000545730.jpg'\n",
      "\n",
      "b'000000481573.jpg'\n",
      "b'000000058029.jpg'\n",
      "b'000000542856.jpg'\n",
      "step 52, loss 15.2655, focal_loss 29.9852, pull_loss 0.0194198, push_loss 0.0466633, offset_loss 0.479609, time 5.67478, lr 0.00025\n",
      "b'000000399462.jpg'\n",
      "b'000000027620.jpg'\n",
      "b'000000049259.jpg'\n",
      "b'000000249219.jpg'\n",
      "b'000000400573.jpg'\n",
      "b'000000491757.jpg'\n",
      "b'000000276804.jpg'\n",
      "b'000000101884.jpg'\n",
      "b'000000046497.jpg'\n",
      "b'000000018833.jpg'\n",
      "step 53, loss 21.9445, focal_loss 43.4347, pull_loss 0.0161581, push_loss 0.0899631, offset_loss 0.348186, time 5.65461, lr 0.00025\n",
      "b'000000328337.jpg'\n",
      "b'000000010995.jpg'\n",
      "b'000000374083.jpg'\n",
      "b'000000319184.jpg'\n",
      "b'000000330554.jpg'\n",
      "b'000000091406.jpg'\n",
      "b'000000227044.jpg'\n",
      "b'000000172977.jpg'\n",
      "b'000000275058.jpg'\n",
      "b'000000575187.jpg'\n",
      "step 54, loss 30.7889, focal_loss 61.0795, pull_loss 0.028706, push_loss 0.0502024, offset_loss 0.419417, time 5.61043, lr 0.00025\n",
      "b'000000525083.jpg'\n",
      "b'000000006012.jpg'\n",
      "b'000000322844.jpg'\n",
      "b'000000568147.jpg'\n",
      "b'000000244592.jpg'\n",
      "b'000000244181.jpg'\n",
      "b'000000210273.jpg'\n",
      "b'000000379533.jpg'\n",
      "b'000000115245.jpg'\n",
      "b'000000361238.jpg'\n",
      "step 55, loss 21.2344, focal_loss 41.9868, pull_loss 0.0128159, push_loss 0.0527396, offset_loss 0.416346, time 5.63746, lr 0.00025\n",
      "b'000000267434.jpg'\n",
      "b'000000156643.jpg'\n",
      "b'000000037751.jpg'\n",
      "b'000000425702.jpg'\n",
      "b'000000370813.jpg'\n",
      "b'000000286422.jpg'\n",
      "b'000000284279.jpg'\n",
      "b'000000410428.jpg'\n",
      "b'000000060102.jpg'\n",
      "b'000000537964.jpg'\n",
      "step 56, loss 20.8757, focal_loss 41.2008, pull_loss 0.00713363, push_loss 0.0649959, offset_loss 0.478409, time 5.66046, lr 0.00025\n",
      "b'000000088218.jpg'\n",
      "b'000000554579.jpg'\n",
      "b'000000414340.jpg'\n",
      "b'000000304291.jpg'\n",
      "b'000000293245.jpg'\n",
      "b'000000453634.jpg'\n",
      "b'000000096825.jpg'\n",
      "b'000000229948.jpg'\n",
      "b'000000203629.jpg'\n",
      "b'000000506279.jpg'\n",
      "step 57, loss 15.9262, focal_loss 31.3768, pull_loss 0.0143858, push_loss 0.0558145, offset_loss 0.405364, time 5.69297, lr 0.00025\n",
      "b'000000245764.jpg'\n",
      "b'000000157046.jpg'\n",
      "b'000000447465.jpg'\n",
      "b'000000143998.jpg'\n",
      "b'000000127955.jpg'\n",
      "b'000000459634.jpg'\n",
      "b'000000222991.jpg'\n",
      "b'000000419379.jpg'\n",
      "b'000000331569.jpg'\n",
      "b'000000423944.jpg'\n",
      "step 58, loss 21.4615, focal_loss 42.442, pull_loss 0.0119681, push_loss 0.0411813, offset_loss 0.42781, time 5.66065, lr 0.00025\n",
      "b'000000180792.jpg'\n",
      "b'000000025424.jpg'\n",
      "b'000000520832.jpg'\n",
      "b'000000246522.jpg'\n",
      "b'000000129945.jpg'\n",
      "b'000000370042.jpg'\n",
      "b'000000384651.jpg'\n",
      "b'000000441468.jpg'\n",
      "b'000000231339.jpg'\n",
      "b'000000261888.jpg'\n",
      "step 59, loss 29.0342, focal_loss 57.5447, pull_loss 0.0182029, push_loss 0.0398152, offset_loss 0.465787, time 5.67127, lr 0.00025\n",
      "b'000000017115.jpg'\n",
      "b'000000343076.jpg'\n",
      "b'000000290163.jpg'\n",
      "b'000000311394.jpg'\n",
      "b'000000078032.jpg'\n",
      "b'000000496722.jpg'b'000000328286.jpg'\n",
      "\n",
      "b'000000394611.jpg'\n",
      "b'000000431693.jpg'\n",
      "b'000000306136.jpg'\n",
      "step 60, loss 34.5828, focal_loss 68.7033, pull_loss 0.0197059, push_loss 0.0483913, offset_loss 0.394135, time 5.64736, lr 0.00025\n",
      "b'000000079969.jpg'\n",
      "b'000000295797.jpg'\n",
      "b'000000544605.jpg'\n",
      "b'000000540928.jpg'\n",
      "b'000000233771.jpg'\n",
      "b'000000540502.jpg'\n",
      "b'000000187243.jpg'\n",
      "b'000000397279.jpg'\n",
      "b'000000022755.jpg'\n",
      "b'000000205289.jpg'\n",
      "b'000000559348.jpg'\n",
      "b'000000384350.jpg'\n",
      "b'000000025228.jpg'\n",
      "b'000000372466.jpg'\n",
      "b'000000185473.jpg'\n",
      "step 61, loss 15.668, focal_loss 30.866, pull_loss 0.0109165, push_loss 0.0577518, offset_loss 0.40131, time 5.65908, lr 0.00025\n",
      "b'000000062353.jpg'\n",
      "b'000000032735.jpg'\n",
      "b'000000479732.jpg'\n",
      "b'000000023359.jpg'\n",
      "b'000000405279.jpg'\n",
      "b'000000341828.jpg'\n",
      "b'000000066926.jpg'\n",
      "b'000000416170.jpg'\n",
      "b'000000114884.jpg'\n",
      "b'000000193494.jpg'\n",
      "step 62, loss 21.2165, focal_loss 41.995, pull_loss 0.00738962, push_loss 0.109018, offset_loss 0.321489, time 5.65786, lr 0.00025\n",
      "b'000000288862.jpg'\n",
      "b'000000529568.jpg'\n",
      "b'000000454067.jpg'\n",
      "b'000000369812.jpg'\n",
      "b'000000350148.jpg'\n",
      "b'000000416343.jpg'\n",
      "b'000000481413.jpg'\n",
      "b'000000164363.jpg'\n",
      "b'000000273132.jpg'\n",
      "b'000000536073.jpg'\n",
      "step 63, loss 22.2477, focal_loss 44.0221, pull_loss 0.0116277, push_loss 0.0747403, offset_loss 0.386958, time 5.66351, lr 0.00025\n",
      "b'000000040757.jpg'\n",
      "b'000000134882.jpg'\n",
      "b'000000400044.jpg'\n",
      "b'000000459887.jpg'\n",
      "b'000000356427.jpg'\n",
      "b'000000417043.jpg'\n",
      "b'000000190007.jpg'b'000000173008.jpg'\n",
      "\n",
      "b'000000440507.jpg'\n",
      "b'000000357430.jpg'\n",
      "step 64, loss 25.3633, focal_loss 50.1915, pull_loss 0.0201171, push_loss 0.0456542, offset_loss 0.469407, time 5.68513, lr 0.00025\n",
      "b'000000466986.jpg'\n",
      "b'000000219485.jpg'\n",
      "b'000000359855.jpg'\n",
      "b'000000486479.jpg'\n",
      "b'000000146498.jpg'\n",
      "b'000000484760.jpg'\n",
      "b'000000038048.jpg'\n",
      "b'000000368982.jpg'\n",
      "b'000000085157.jpg'\n",
      "b'000000382743.jpg'\n",
      "step 65, loss 15.7742, focal_loss 31.0474, pull_loss 0.0118778, push_loss 0.0508318, offset_loss 0.438262, time 5.6653, lr 0.00025\n",
      "b'000000511453.jpg'b'000000477623.jpg'\n",
      "\n",
      "b'000000377723.jpg'\n",
      "b'000000577735.jpg'\n",
      "b'000000264335.jpg'\n",
      "b'000000216419.jpg'b'000000526751.jpg'\n",
      "\n",
      "b'000000532575.jpg'\n",
      "b'000000580294.jpg'\n",
      "b'000000070048.jpg'\n",
      "step 66, loss 41.6099, focal_loss 82.7084, pull_loss 0.0164064, push_loss 0.0649146, offset_loss 0.430198, time 5.67979, lr 0.00025\n",
      "b'000000000139.jpg'\n",
      "b'000000029984.jpg'\n",
      "b'000000430377.jpg'\n",
      "b'000000329041.jpg'\n",
      "b'000000466339.jpg'\n",
      "b'000000425361.jpg'\n",
      "b'000000462904.jpg'\n",
      "b'000000467848.jpg'\n",
      "b'000000162543.jpg'\n",
      "b'000000121591.jpg'\n",
      "step 67, loss 38.3853, focal_loss 76.3157, pull_loss 0.00795441, push_loss 0.057224, offset_loss 0.389724, time 5.66042, lr 0.00025\n",
      "b'000000313034.jpg'\n",
      "b'000000069356.jpg'\n",
      "b'000000129756.jpg'\n",
      "b'000000243075.jpg'\n",
      "b'000000079144.jpg'\n",
      "b'000000439854.jpg'\n",
      "b'000000051976.jpg'\n",
      "b'000000013291.jpg'\n",
      "b'000000501523.jpg'\n",
      "b'000000255749.jpg'\n",
      "step 68, loss 13.6985, focal_loss 26.8506, pull_loss 0.0136292, push_loss 0.0596056, offset_loss 0.473211, time 5.64228, lr 0.00025\n",
      "b'000000080340.jpg'\n",
      "b'000000370270.jpg'\n",
      "b'000000380706.jpg'\n",
      "b'000000020059.jpg'\n",
      "b'000000177893.jpg'\n",
      "b'000000017178.jpg'\n",
      "b'000000319935.jpg'\n",
      "b'000000365387.jpg'\n",
      "b'000000031050.jpg'\n",
      "b'000000525322.jpg'\n",
      "step 69, loss 17.808, focal_loss 35.0831, pull_loss 0.00928924, push_loss 0.0520401, offset_loss 0.47152, time 5.66949, lr 0.00025\n",
      "b'000000273642.jpg'\n",
      "b'000000007991.jpg'\n",
      "b'000000294350.jpg'\n",
      "b'000000482970.jpg'\n",
      "b'000000127476.jpg'\n",
      "b'000000165713.jpg'\n",
      "b'000000131386.jpg'\n",
      "b'000000336232.jpg'\n",
      "b'000000371677.jpg'\n",
      "b'000000087476.jpg'\n",
      "step 70, loss 15.0594, focal_loss 29.5839, pull_loss 0.00961929, push_loss 0.12807, offset_loss 0.397222, time 5.63622, lr 0.00025\n",
      "b'000000154425.jpg'\n",
      "b'000000361621.jpg'\n",
      "b'000000299355.jpg'\n",
      "b'000000087742.jpg'\n",
      "b'000000458054.jpg'\n",
      "b'000000369310.jpg'b'000000173044.jpg'\n",
      "\n",
      "b'000000414676.jpg'\n",
      "b'000000102411.jpg'\n",
      "b'000000136033.jpg'\n",
      "b'000000526197.jpg'b'000000273420.jpg'\n",
      "\n",
      "b'000000061171.jpg'\n",
      "b'000000419653.jpg'\n",
      "b'000000324715.jpg'\n",
      "step 71, loss 15.4877, focal_loss 30.5154, pull_loss 0.0099922, push_loss 0.067899, offset_loss 0.382055, time 5.68, lr 0.00025\n",
      "b'000000429598.jpg'b'000000255718.jpg'\n",
      "\n",
      "b'000000500270.jpg'\n",
      "b'000000271728.jpg'\n",
      "b'000000104666.jpg'\n",
      "b'000000188592.jpg'\n",
      "b'000000449579.jpg'\n",
      "b'000000157138.jpg'\n",
      "b'000000133819.jpg'\n",
      "b'000000356094.jpg'\n",
      "step 72, loss 11.9465, focal_loss 23.3905, pull_loss 0.00566789, push_loss 0.0417272, offset_loss 0.455124, time 5.66982, lr 0.00025\n",
      "b'000000173830.jpg'\n",
      "b'000000486112.jpg'\n",
      "b'000000328238.jpg'\n",
      "b'000000082715.jpg'\n",
      "b'000000030828.jpg'\n",
      "b'000000231097.jpg'\n",
      "b'000000127182.jpg'\n",
      "b'000000427655.jpg'\n",
      "b'000000480936.jpg'\n",
      "b'000000007888.jpg'\n",
      "step 73, loss 29.4307, focal_loss 58.2848, pull_loss 0.0103173, push_loss 0.0889256, offset_loss 0.477372, time 5.66086, lr 0.00025\n",
      "b'000000183104.jpg'\n",
      "b'000000417285.jpg'\n",
      "b'000000394328.jpg'\n",
      "b'000000013729.jpg'\n",
      "b'000000166287.jpg'\n",
      "b'000000254814.jpg'\n",
      "b'000000082765.jpg'\n",
      "b'000000426203.jpg'\n",
      "b'000000567011.jpg'\n",
      "b'000000167572.jpg'\n",
      "step 74, loss 18.6856, focal_loss 36.9823, pull_loss 0.00745584, push_loss 0.0523846, offset_loss 0.329133, time 5.65868, lr 0.00025\n",
      "b'000000311883.jpg'\n",
      "b'000000406417.jpg'\n",
      "b'000000081766.jpg'\n",
      "b'000000380711.jpg'\n",
      "b'000000567740.jpg'\n",
      "b'000000396568.jpg'\n",
      "b'000000066706.jpg'\n",
      "b'000000415536.jpg'\n",
      "b'000000568584.jpg'\n",
      "b'000000171611.jpg'\n",
      "step 75, loss 13.6833, focal_loss 26.9302, pull_loss 0.00715318, push_loss 0.0365024, offset_loss 0.392842, time 5.61583, lr 0.00025\n",
      "b'000000228771.jpg'\n",
      "b'000000358195.jpg'\n",
      "b'000000490171.jpg'\n",
      "b'000000289343.jpg'\n",
      "b'000000462031.jpg'\n",
      "b'000000475678.jpg'\n",
      "b'000000465129.jpg'\n",
      "b'000000001993.jpg'\n",
      "b'000000176847.jpg'\n",
      "b'000000161925.jpg'\n",
      "step 76, loss 16.3692, focal_loss 32.2781, pull_loss 0.0114749, push_loss 0.0427458, offset_loss 0.406086, time 5.62999, lr 0.00025\n",
      "b'000000142585.jpg'\n",
      "b'000000175364.jpg'\n",
      "b'000000119516.jpg'\n",
      "b'000000389381.jpg'\n",
      "b'000000022935.jpg'\n",
      "b'000000341094.jpg'\n",
      "b'000000121506.jpg'\n",
      "b'000000091500.jpg'\n",
      "b'000000017436.jpg'\n",
      "b'000000334719.jpg'\n",
      "step 77, loss 30.3663, focal_loss 60.2087, pull_loss 0.0108264, push_loss 0.0411684, offset_loss 0.471952, time 5.67341, lr 0.00025\n",
      "b'000000142324.jpg'\n",
      "b'000000144932.jpg'\n",
      "b'000000096549.jpg'\n",
      "b'000000506707.jpg'\n",
      "b'000000273712.jpg'\n",
      "b'000000304545.jpg'\n",
      "b'000000359677.jpg'\n",
      "b'000000134856.jpg'\n",
      "b'000000012576.jpg'\n",
      "b'000000313562.jpg'\n",
      "step 78, loss 13.9274, focal_loss 27.3359, pull_loss 0.0049616, push_loss 0.0927724, offset_loss 0.421231, time 5.61643, lr 0.00025\n",
      "b'000000360943.jpg'\n",
      "b'000000057244.jpg'\n",
      "b'000000289516.jpg'\n",
      "b'000000236426.jpg'\n",
      "b'000000344888.jpg'\n",
      "b'000000005060.jpg'\n",
      "b'000000295138.jpg'\n",
      "b'000000304560.jpg'\n",
      "b'000000494427.jpg'\n",
      "b'000000524850.jpg'\n",
      "step 79, loss 13.5835, focal_loss 26.6942, pull_loss 0.00677542, push_loss 0.0518788, offset_loss 0.414094, time 5.67056, lr 0.00025\n",
      "b'000000539445.jpg'\n",
      "b'000000292908.jpg'\n",
      "b'000000206831.jpg'\n",
      "b'000000458663.jpg'\n",
      "b'000000491613.jpg'\n",
      "b'000000424135.jpg'\n",
      "b'000000453860.jpg'\n",
      "b'000000065798.jpg'\n",
      "b'000000528862.jpg'\n",
      "b'000000322352.jpg'\n",
      "step 80, loss 13.669, focal_loss 26.9104, pull_loss 0.00741407, push_loss 0.0625389, offset_loss 0.357658, time 5.61983, lr 0.00025\n",
      "b'000000270705.jpg'\n",
      "b'000000222235.jpg'\n",
      "b'000000043314.jpg'\n",
      "b'000000366178.jpg'\n",
      "b'000000578545.jpg'\n",
      "b'000000236166.jpg'\n",
      "b'000000351810.jpg'\n",
      "b'000000289938.jpg'\n",
      "b'000000363207.jpg'\n",
      "b'000000016958.jpg'\n",
      "b'000000461036.jpg'b'000000355677.jpg'\n",
      "\n",
      "b'000000040083.jpg'\n",
      "b'000000175443.jpg'\n",
      "b'000000498286.jpg'\n",
      "step 81, loss 17.4199, focal_loss 34.3776, pull_loss 0.0111083, push_loss 0.0457484, offset_loss 0.405382, time 5.67646, lr 0.00025\n",
      "b'000000289659.jpg'\n",
      "b'000000312406.jpg'\n",
      "b'000000002261.jpg'\n",
      "b'000000410221.jpg'\n",
      "b'000000185250.jpg'\n",
      "b'000000378139.jpg'\n",
      "b'000000556158.jpg'\n",
      "b'000000129416.jpg'\n",
      "b'000000484351.jpg'\n",
      "b'000000088462.jpg'\n",
      "step 82, loss 17.517, focal_loss 34.5518, pull_loss 0.00527549, push_loss 0.0698902, offset_loss 0.406965, time 5.60028, lr 0.00025\n",
      "b'000000110211.jpg'\n",
      "b'000000167353.jpg'\n",
      "b'000000185599.jpg'\n",
      "b'000000525155.jpg'\n",
      "b'000000427997.jpg'\n",
      "b'000000527616.jpg'\n",
      "b'000000567898.jpg'\n",
      "b'000000351096.jpg'\n",
      "b'000000543043.jpg'\n",
      "b'000000506004.jpg'\n",
      "step 83, loss 21.6208, focal_loss 42.7531, pull_loss 0.00975507, push_loss 0.0559954, offset_loss 0.422702, time 5.61923, lr 0.00025\n",
      "b'000000161128.jpg'\n",
      "b'000000303863.jpg'\n",
      "b'000000013546.jpg'\n",
      "b'000000270297.jpg'\n",
      "b'000000218997.jpg'\n",
      "b'000000308193.jpg'b'000000500613.jpg'\n",
      "\n",
      "b'000000025386.jpg'\n",
      "b'000000251119.jpg'\n",
      "b'000000479030.jpg'\n",
      "step 84, loss 11.4576, focal_loss 22.4419, pull_loss 0.00622776, push_loss 0.0607667, offset_loss 0.406269, time 5.70288, lr 0.00025\n",
      "b'000000278006.jpg'\n",
      "b'000000516316.jpg'\n",
      "b'000000184978.jpg'\n",
      "b'000000512330.jpg'\n",
      "b'000000323799.jpg'\n",
      "b'000000561223.jpg'\n",
      "b'000000501005.jpg'\n",
      "b'000000128112.jpg'\n",
      "b'000000364636.jpg'\n",
      "b'000000320696.jpg'\n",
      "step 85, loss 25.0324, focal_loss 49.5855, pull_loss 0.0094177, push_loss 0.0430137, offset_loss 0.426974, time 5.63431, lr 0.00025\n",
      "b'000000031296.jpg'\n",
      "b'000000160728.jpg'\n",
      "b'000000063740.jpg'\n",
      "b'000000541664.jpg'\n",
      "b'000000157098.jpg'\n",
      "b'000000144333.jpg'\n",
      "b'000000023230.jpg'\n",
      "b'000000267351.jpg'\n",
      "b'000000106048.jpg'\n",
      "b'000000157390.jpg'\n",
      "step 86, loss 22.8429, focal_loss 45.2579, pull_loss 0.012941, push_loss 0.0644851, offset_loss 0.35043, time 5.64856, lr 0.00025\n",
      "b'000000104603.jpg'\n",
      "b'000000072852.jpg'\n",
      "b'000000093261.jpg'\n",
      "b'000000182202.jpg'\n",
      "b'000000231822.jpg'\n",
      "b'000000270244.jpg'\n",
      "b'000000201025.jpg'\n",
      "b'000000008629.jpg'\n",
      "b'000000494634.jpg'\n",
      "b'000000256941.jpg'\n",
      "step 87, loss 19.2469, focal_loss 38.0039, pull_loss 0.00891487, push_loss 0.0529709, offset_loss 0.42795, time 5.68732, lr 0.00025\n",
      "b'000000348216.jpg'\n",
      "b'000000491130.jpg'\n",
      "b'000000250205.jpg'\n",
      "b'000000098853.jpg'\n",
      "b'000000446651.jpg'\n",
      "b'000000269932.jpg'\n",
      "b'000000555412.jpg'\n",
      "b'000000352582.jpg'\n",
      "b'000000041488.jpg'\n",
      "b'000000212166.jpg'\n",
      "step 88, loss 11.9532, focal_loss 23.3857, pull_loss 0.00696926, push_loss 0.0493473, offset_loss 0.464328, time 5.71138, lr 0.00025\n",
      "b'000000393014.jpg'\n",
      "b'000000298738.jpg'\n",
      "b'000000409542.jpg'\n",
      "b'000000296969.jpg'\n",
      "b'000000527029.jpg'\n",
      "b'000000372718.jpg'\n",
      "b'000000283785.jpg'\n",
      "b'000000064574.jpg'\n",
      "b'000000492937.jpg'\n",
      "b'000000148999.jpg'\n",
      "step 89, loss 22.0737, focal_loss 43.7027, pull_loss 0.00952622, push_loss 0.067015, offset_loss 0.368255, time 5.6333, lr 0.00025\n",
      "b'000000226903.jpg'\n",
      "b'000000399764.jpg'\n",
      "b'000000199551.jpg'\n",
      "b'000000006771.jpg'\n",
      "b'000000431876.jpg'\n",
      "b'000000220310.jpg'\n",
      "b'000000312192.jpg'\n",
      "b'000000404601.jpg'\n",
      "b'000000352760.jpg'\n",
      "b'000000163314.jpg'\n",
      "step 90, loss 14.3271, focal_loss 28.183, pull_loss 0.01011, push_loss 0.0669965, offset_loss 0.394035, time 5.64891, lr 0.00025\n",
      "b'000000121153.jpg'\n",
      "b'000000189775.jpg'\n",
      "b'000000410650.jpg'\n",
      "b'000000269113.jpg'\n",
      "b'000000051598.jpg'\n",
      "b'000000220764.jpg'\n",
      "b'000000537812.jpg'\n",
      "b'000000575815.jpg'\n",
      "b'000000334483.jpg'\n",
      "b'000000378605.jpg'\n",
      "b'000000396863.jpg'\n",
      "b'000000229997.jpg'\n",
      "b'000000008899.jpg'\n",
      "b'000000039785.jpg'\n",
      "b'000000023937.jpg'\n",
      "step 91, loss 12.3499, focal_loss 24.1115, pull_loss 0.00623462, push_loss 0.0885647, offset_loss 0.49359, time 5.68822, lr 0.00025\n",
      "b'000000177065.jpg'\n",
      "b'000000577932.jpg'\n",
      "b'000000488664.jpg'\n",
      "b'000000089761.jpg'\n",
      "b'000000578792.jpg'\n",
      "b'000000438876.jpg'\n",
      "b'000000174004.jpg'\n",
      "b'000000464358.jpg'\n",
      "b'000000493284.jpg'\n",
      "b'000000180878.jpg'\n",
      "step 92, loss 14.3015, focal_loss 28.0815, pull_loss 0.00699058, push_loss 0.0756063, offset_loss 0.438842, time 5.67462, lr 0.00025\n",
      "b'000000130586.jpg'\n",
      "b'000000192047.jpg'\n",
      "b'000000425221.jpg'\n",
      "b'000000493864.jpg'\n",
      "b'000000360951.jpg'\n",
      "b'000000414510.jpg'\n",
      "b'000000133343.jpg'\n",
      "b'000000418696.jpg'\n",
      "b'000000080153.jpg'\n",
      "b'000000101762.jpg'\n",
      "step 93, loss 11.0704, focal_loss 21.6599, pull_loss 0.00756374, push_loss 0.0542217, offset_loss 0.419135, time 5.65409, lr 0.00025\n",
      "b'000000224119.jpg'\n",
      "b'000000309391.jpg'\n",
      "b'000000399560.jpg'\n",
      "b'000000223747.jpg'\n",
      "b'000000113235.jpg'\n",
      "b'000000455267.jpg'\n",
      "b'000000551794.jpg'\n",
      "b'000000228942.jpg'\n",
      "b'000000400082.jpg'\n",
      "b'000000482477.jpg'\n",
      "step 94, loss 23.6893, focal_loss 46.9048, pull_loss 0.0115609, push_loss 0.0701859, offset_loss 0.39205, time 5.61945, lr 0.00025\n",
      "b'000000570664.jpg'\n",
      "b'000000495732.jpg'\n",
      "b'000000276284.jpg'\n",
      "b'000000244833.jpg'\n",
      "b'000000080057.jpg'\n",
      "b'000000063047.jpg'\n",
      "b'000000030675.jpg'\n",
      "b'000000199681.jpg'\n",
      "b'000000369503.jpg'\n",
      "b'000000199395.jpg'\n",
      "step 95, loss 14.3634, focal_loss 28.2723, pull_loss 0.00958761, push_loss 0.0536266, offset_loss 0.391335, time 5.6522, lr 0.00025\n",
      "b'000000417465.jpg'\n",
      "b'000000414673.jpg'\n",
      "b'000000452784.jpg'\n",
      "b'000000315001.jpg'\n",
      "b'000000470173.jpg'\n",
      "b'000000082986.jpg'\n",
      "b'000000544811.jpg'\n",
      "b'000000566042.jpg'\n",
      "b'000000360325.jpg'\n",
      "b'000000480122.jpg'\n",
      "step 96, loss 19.8957, focal_loss 39.3844, pull_loss 0.0107401, push_loss 0.0390056, offset_loss 0.357197, time 5.66526, lr 0.00025\n",
      "b'000000578967.jpg'\n",
      "b'000000267670.jpg'\n",
      "b'000000435208.jpg'\n",
      "b'000000253452.jpg'\n",
      "b'000000521719.jpg'\n",
      "b'000000121586.jpg'\n",
      "b'000000150726.jpg'\n",
      "b'000000166277.jpg'\n",
      "b'000000133087.jpg'\n",
      "b'000000253742.jpg'\n",
      "step 97, loss 11.9088, focal_loss 23.1774, pull_loss 0.00776594, push_loss 0.141169, offset_loss 0.491267, time 5.66332, lr 0.00025\n",
      "b'000000464824.jpg'\n",
      "b'000000307598.jpg'\n",
      "b'000000139077.jpg'\n",
      "b'000000383289.jpg'\n",
      "b'000000092416.jpg'\n",
      "b'000000221693.jpg'\n",
      "b'000000131444.jpg'\n",
      "b'000000327592.jpg'\n",
      "b'000000306582.jpg'\n",
      "b'000000418281.jpg'\n",
      "step 98, loss 13.311, focal_loss 26.1055, pull_loss 0.00885148, push_loss 0.0393974, offset_loss 0.468217, time 5.65573, lr 0.00025\n",
      "b'000000456015.jpg'\n",
      "b'000000428867.jpg'\n",
      "b'000000558114.jpg'\n",
      "b'000000289586.jpg'\n",
      "b'000000347174.jpg'\n",
      "b'000000526103.jpg'\n",
      "b'000000445248.jpg'\n",
      "b'000000138550.jpg'\n",
      "b'000000148620.jpg'\n",
      "b'000000219440.jpg'\n",
      "step 99, loss 26.997, focal_loss 53.5727, pull_loss 0.0133881, push_loss 0.0586311, offset_loss 0.34927, time 5.67094, lr 0.00025\n"
     ]
    }
   ],
   "source": [
    "# actually train the net         \n",
    "if __name__==\"__main__\":\n",
    "\n",
    "    t=Train()\n",
    "    steps, total_loss = t.train_single()\n",
    "    #t.train_mult()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mhQF1XYEMnUP"
   },
   "source": [
    "Here, the overall loss is visualized to make sure that training proceeds successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "tpkitE2JucIj",
    "outputId": "1416a136-9bf9-4486-a188-47e88055557a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.axis([0, 100, 20, 10000])\n",
    "line1, = plt.plot(steps, total_loss)\n",
    "plt.xlabel(\"Training steps\")\n",
    "plt.ylabel(\"Total Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "58r61QmFNEL8"
   },
   "source": [
    "For reasons of computational tractability, the model is not actually tested since it was also only trained as a toy example. The code below can be used to test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ntqlkLVQNCkP"
   },
   "outputs": [],
   "source": [
    "# test = Test()\n",
    "# test.test(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ao8h4jwsevmf"
   },
   "source": [
    "### References\n",
    "[1] Law, H., & Deng, J. (2018). Cornernet: Detecting objects as paired keypoints. In Proceedings of the European conference on computer vision (ECCV) (pp. 734-750).\n",
    "\n",
    "[2] https://github.com/makalo/CornerNet"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "xqT4rLIzokBG",
    "npXSAqxKXUUF",
    "WY3rD6mkCyDf",
    "SVfngMxLKUZp"
   ],
   "name": "CornerNet-ADL.ipynb",
   "provenance": []
  },
  "jupytext": {
   "formats": "ipynb,Rmd"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
